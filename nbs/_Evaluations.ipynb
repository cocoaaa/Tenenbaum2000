{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define model architecture\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_path = get_best_ckpt(model,verbose=True)\n",
    "# load_model(model, ckpt_path)\n",
    "# load_best_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recons of inputs from training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mean, train_std = dm.train_mean, dm.train_std\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for mode in ['train', 'val']:\n",
    "        dl = getattr(model, f\"{mode}_dataloader\")()\n",
    "        x,y = next(iter(dl))\n",
    "        x = x.to(model.device)\n",
    "        x_recon = model.generate(x)\n",
    "        \n",
    "        # unnormalize for visualization\n",
    "        x = x.cpu()\n",
    "        x_recon = x_recon.cpu()\n",
    "        x_unnormed = unnormalize(x, train_mean, train_std)\n",
    "        x_recon_unnormed = unnormalize(x_recon, train_mean, train_std)\n",
    "        show_timgs(x_unnormed, title=f\"{mode} dataset\", cmap='gray')\n",
    "        show_timgs(x_recon_unnormed, title=f\"{mode}: recon\", cmap='gray')\n",
    "        show_timgs(LinearRescaler()(x_recon_unnormed), title=f\"{mode}: recon\", cmap='gray')\n",
    "        \n",
    "        # Print out\n",
    "        info(x, f\"{mode}_x\")\n",
    "        info(x_recon, f\"{mode}_x_recon\")\n",
    "        print(\"===\")\n",
    "        info(x_unnormed, f\"{mode}_x_unnormed\")\n",
    "        info(x_recon_unnormed, f\"{mode}_x_recon_unnormed\")\n",
    "        \n",
    "        # Log input-recon grid to TB\n",
    "        input_grid = torchvision.utils.make_grid(x_unnormed) # (C, gridh, gridw)\n",
    "        recon_grid = torchvision.utils.make_grid(x_recon_unnormed) # (C, gridh, gridw)\n",
    "#         normed_recon_grid = torchvision.utils.make_grid(LinearRescaler()(x_recon_unnormed))\n",
    "        grid = torch.cat([input_grid, recon_grid], dim=-1) #inputs | recons\n",
    "        tb_logger.experiment.add_image(f\"{mode}/recons\", grid, global_step=0)\n",
    "                            \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize embeddings\n",
    "- collect a batch of inputs -> encoder -> [mu, log_var] -> sample -> a batch of z's (embeddings)\n",
    "- use tb logger\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    x, y = next(iter(trainer.train_dataloader))\n",
    "    mu, log_var = model.encode(x)\n",
    "    z = model.reparameterize(mu, log_var)\n",
    "#     out = model.get_embeddings(x) # dict of mu, log_var, z\n",
    "#     z = out['z']\n",
    "    \n",
    "    # log embedding to tensorboard \n",
    "    writer = model.logger.experiment\n",
    "    writer.add_embedding(z,\n",
    "                         label_img=LinearRescaler()(x), \n",
    "                         metadata=y.tolist(),\n",
    "                         global_step=trainer.global_step, #todo\n",
    "                        )\n",
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize original images of the close neighbors in the latent space\n",
    "- Compute pairwise distance using cosine similarity\n",
    "- For each row (ie. a latent code), get the index of the smallest values. \n",
    "- Select the images in the batch x and visualize (can do this all in show_timgs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import pairwise_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    x, y = next(iter(trainer.train_dataloader))\n",
    "    mu, log_var = model.encode(x)\n",
    "    z = model.reparameterize(mu, log_var)\n",
    "    #     out = model.get_embeddings(x) # dict of mu, log_var, z\n",
    "    #     z = out['z']metric = 'cosine'\n",
    "    pdists = pairwise_distances(z.numpy(), metric=metric)\n",
    "    plt.imshow(pdists, cmap='gray')\n",
    "    plt.title(\"Pairwise dists of z's\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    \n",
    "    # smaller values means closer in distance\n",
    "    n_ngbrs = 5\n",
    "    n_rows = 100\n",
    "    \n",
    "    selected_rows = np.random.choice(len(x), size=n_rows)\n",
    "    for idx in selected_rows:\n",
    "        args = np.argsort(pdists[idx])[:n_ngbrs]\n",
    "#         print(args)\n",
    "        show_timgs(LinearRescaler()(x[args]), cmap='gray', factor=2, \n",
    "                   nrows=1, title=f'Nearest of img {idx}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# smaller values means closer in distance\n",
    "n_ngbrs = 5\n",
    "n_rows = 10\n",
    "selected_rows = np.random.choice(len(x), size=n_rows)\n",
    "for idx in selected_rows:\n",
    "    args = np.argsort(pdists[idx])[:n_ngbrs]\n",
    "    print(args)\n",
    "    show_timgs(LinearRescaler()(x[args]), cmap='gray', factor=2, \n",
    "               nrows=1, title=f'Nearest of img {idx}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argsort(pdists[1])[:n_ngbrs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_ngbrs = 5\n",
    "args = np.argsort(pdists, axis=1)[:n_ngbrs]\n",
    "print(args.shape)\n",
    "# show_timgs(LinearRescaler()(x[args]), cmap='gray', factor=2, nrows=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Latent Space Traversal\n",
    "1. Linear traversal in a single dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen_dim = 0 # must be in range(latent_dim)\n",
    "fixed_vec = torch.randn((1, model.latent_dim-1))\n",
    "fixed_values = fixed_vec.repeat((n_samples,1))\n",
    "n_samples = 16\n",
    "zi_min, zi_max = -2,2\n",
    "varying = torch.linspace(zi_min, zi_max, n_samples).view((-1,1))\n",
    "\n",
    "varying.shape,fixed_values.shape\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_from(a_col:torch.Tensor, other_cols:torch.Tensor, ind):\n",
    "    \"\"\"\n",
    "    Make a tensor from a column vector and a matrx containing all the other columns\n",
    "    by inserting the `onc_column` at the final matrix's `ind`th column.\n",
    "    \"\"\"\n",
    "    assert a_\n",
    "    n_cols = 1 + \n",
    "    out = a_col.new_zeros(("
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:test]",
   "language": "python",
   "name": "conda-env-test-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
