{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,sys\n",
    "import re\n",
    "import math\n",
    "from datetime import datetime\n",
    "import time\n",
    "sys.dont_write_bytecode = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pathlib import Path\n",
    "from typing import List, Set, Dict, Tuple, Optional, Iterable, Mapping, Union, Callable, TypeVar\n",
    "\n",
    "from pprint import pprint\n",
    "from ipdb import set_trace as brpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from  torch.linalg import norm as tnorm\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.core.lightning import LightningModule\n",
    "from pytorch_lightning import loggers as pl_loggers\n",
    "from pytorch_lightning.tuner.tuning import Tuner\n",
    "\n",
    "\n",
    "# Select Visible GPU\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Path \n",
    "1. Add project root and src folders to `sys.path`\n",
    "2. Set DATA_ROOT to `maptile_v2` folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "this_nb_path = Path(os.getcwd())\n",
    "ROOT = this_nb_path.parent\n",
    "SRC = ROOT/'src'\n",
    "DATA_ROOT = Path(\"/data/hayley-old/maptiles_v2/\")\n",
    "paths2add = [this_nb_path, ROOT]\n",
    "\n",
    "print(\"Project root: \", str(ROOT))\n",
    "print('Src folder: ', str(SRC))\n",
    "print(\"This nb path: \", str(this_nb_path))\n",
    "\n",
    "\n",
    "for p in paths2add:\n",
    "    if str(p) not in sys.path:\n",
    "        sys.path.insert(0, str(p))\n",
    "        print(f\"\\n{str(p)} added to the path.\")\n",
    "        \n",
    "print(sys.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data.datasets.maptiles import MaptilesDataset, MapStyles\n",
    "from src.data.datamodules.maptiles_datamodule import MaptilesDataModule\n",
    "\n",
    "from src.data.transforms.transforms import Identity\n",
    "\n",
    "from src.visualize.utils import show_timgs\n",
    "from src.utils.misc import info\n",
    "from collections import OrderedDict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyTrainer(pl.Trainer):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs) #check if this sets train/val dataloaders\n",
    "        self.num_data = len(self.train_dataloader().dataset)\n",
    "\n",
    "    def get_dl(mode: str, dl_idx:int=0):\n",
    "        if mode == 'train':\n",
    "            dl = getattr(self, \"train_dataloader\")\n",
    "        else:\n",
    "            dl = getattr(self, f\"{mode}_dataloaders\")[dl_idx]\n",
    "        print(dl)\n",
    "        print(dl.dataset)\n",
    "        return dl\n",
    "    \n",
    "    def get_next_batch(mode: str, dl_idx):\n",
    "        dl = self.get_dl(mode, dl_idx)\n",
    "        return next(iter(dl))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start experiment \n",
    "Given a maptile, predict its style as one of OSM, CartoVoyager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models.plmodules.vanilla_vae import VanillaVAE\n",
    "from src.models.plmodules.iwae import IWAE\n",
    "from src.models.plmodules.three_fcs import ThreeFCs\n",
    "\n",
    "from src.data.datamodules.maptiles_datamodule import MaptilesDataModule\n",
    "from src.data.datamodules.mnist_datamodule import MNISTDataModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 128\n",
    "dm = MNISTDataModule(in_shape=(1,32,32), bs=bs)\n",
    "dm.setup('fit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dm.train_ds.show_samples(order='chw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the pl Module\n",
    "model_name = 'iwae' # 'vae'\n",
    "latent_dim = 10\n",
    "hidden_dims = [32,64,128,256]#,512]\n",
    "n_samples = 3\n",
    "act_fn = nn.ReLU()\n",
    "lr = 1e-3\n",
    "\n",
    "def models(model_name: str):\n",
    "    return {'vae': VanillaVAE(in_shape=dm.size(), #dm.in_shape, \n",
    "                        latent_dim=latent_dim,\n",
    "                        hidden_dims=hidden_dims,\n",
    "                        act_fn=act_fn,\n",
    "                        learning_rate=lr),\n",
    "            'iwae': IWAE(\n",
    "                in_shape=dm.size(), #dm.in_shape, \n",
    "                latent_dim=latent_dim,\n",
    "                hidden_dims=hidden_dims,\n",
    "                n_samples=n_samples,\n",
    "                act_fn=act_fn,\n",
    "                learning_rate=lr\n",
    "            )}[model_name]\n",
    "\n",
    "model = models(model_name)\n",
    "# print(dm.hparams)\n",
    "\n",
    "print(model.name)\n",
    "print(model.hparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add Callbacks\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "from src.callbacks.hist_logger import HistogramLogger\n",
    "from src.callbacks.recon_logger import ReconLogger\n",
    "callbacks = [\n",
    "        HistogramLogger(hist_epoch_interval=1),\n",
    "        ReconLogger(recon_epoch_interval=1),\n",
    "#         EarlyStopping('val_loss', patience=10),\n",
    "]\n",
    "\n",
    "# Start the experiment\n",
    "exp_name = f'{model.name}_{dm.name}'\n",
    "tb_logger = pl_loggers.TensorBoardLogger(save_dir=f'{ROOT}/temp-logs', \n",
    "                                         name=exp_name,\n",
    "                                         log_graph=False,\n",
    "                                        default_hp_metric=False)\n",
    "print(tb_logger.log_dir)\n",
    "\n",
    "# Log computational graph\n",
    "# model_wrapper = ModelWrapper(model)\n",
    "# tb_logger.experiment.add_graph(model_wrapper, model.example_input_array.to(model.device))\n",
    "# tb_logger.log_graph(model)\n",
    "\n",
    "trainer_config = {\n",
    "    'gpus':1,\n",
    "    'max_epochs': 100,\n",
    "    'progress_bar_refresh_rate':20,\n",
    "#     'auto_lr_find': True,\n",
    "    'terminate_on_nan':True,\n",
    "#     'num_sanity_val_steps':0.25,\n",
    "    'check_val_every_n_epoch':10,\n",
    "    'logger':tb_logger,\n",
    "    'callbacks':callbacks,\n",
    "}\n",
    "\n",
    "# Instantiate a PL `Trainer` object\n",
    "# trainer = pl.Trainer(fast_dev_run=3)\n",
    "trainer = pl.Trainer(**trainer_config)\n",
    "trainer.fit(model, dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally,\n",
    "# Log this model's hyperparmeters to tensorboard\n",
    "# hparams = dict(model.hparams)\n",
    "# metrics = {'hparam/acc': model.hparams[\"loss\"]}\n",
    "# model.logger.experiment.add_hparams(hparam_dict=hparams,\n",
    "#                                     metric_dict=metrics) #how to store the 'best' value of the metric?\n",
    "# Alternatively, use pl.Logger's method \"log_hyperparameters\"\n",
    "#         logger.log_hyperparams(hparams, metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "1. Reconstructions\n",
    "    - Given x from train/val/test dataset, show N (eg. 16) number of possible reconstruction\n",
    "    - Workflow: \n",
    "        - x --> model.encoder(x) --> theta_z --> sample N latent codes from the Pr(z; theta_z) --> model.decoder(z) for each sampled z's \n",
    "2. Inspect the topology/landscape of the learned latent space\n",
    "    - Latent traversal: Pick a dimension of the latent space. Keep all other dimensions' values constant. Vary the chosen dimenion's values (eg. linearly, spherically) and decode the latent codes. Show the outputs of the decoder.\n",
    "    \n",
    "3. Mutual information\n",
    "    - Between x and x_sample for N number of x_samples.\n",
    "    - Between each dimensions of a latent code\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.distributions import Normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llhs = {}\n",
    "dim_x = model.input_dim()\n",
    "with torch.no_grad():\n",
    "    for mode in ['train', 'val']:\n",
    "        prob_sum = torch.tensor(0.)\n",
    "        n_imgs = 0\n",
    "        dl = getattr(dm, f\"{mode}_dataloader\")()\n",
    "        for (x,y) in dl:           \n",
    "            bs = x.shape[0]\n",
    "            \n",
    "            # sample z -> decoder -> mu_x\n",
    "            z_sample = torch.randn((bs, model.latent_dim), device=model.device)\n",
    "            mu_x = model.decode(z_sample)\n",
    "            \n",
    "            dist = Normal(mu_x, torch.ones(mu_x.shape))\n",
    "            breakpoint()\n",
    "            log_prob = torch.sum(dist.log_prob(x), dim=(1,2,3)) # (bs,1)\n",
    "            prob = log_prob.exp()\n",
    "            \n",
    "            # Accumulate the sum over this batch\n",
    "            prob_sum += torch.sum(prob)\n",
    "            prob_per_dim_sum += torch.sum(prob) / dim_x\n",
    "            n_imgs += bs\n",
    "\n",
    "        # Log of average likelihood of an image\n",
    "        llhs[mode] = (prob_sum/n_imgs).item()\n",
    "        llhs_dim[mode] = (prob_sum/n_imgs).item() \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(llhs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recons of inputs from training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    for mode in ['train', 'val']:\n",
    "        dl = getattr(model, f\"{mode}_dataloader\")()\n",
    "        x,y = next(iter(dl))\n",
    "        x_recon = model.generate(x)\n",
    "        show_timgs(x.detach(), title=f\"{mode} dataset\")\n",
    "        show_timgs(x_recon.detach(), title=f\"{mode}: recon\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    mu,log_var = model.encode(x)\n",
    "    f, ax = plt.subplots(1,2)\n",
    "    ax = ax.flatten()\n",
    "    ax[0].hist(mu, label='mu')\n",
    "    ax[0].set_title('mu')\n",
    "    ax[1].hist(log_var.exp(), label='var')\n",
    "    ax[1].set_title('var')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_var = 1e-4\n",
    "n_tiny_vars = (log_var.exp() < min_var).sum()\n",
    "n_tiny_vars, n_tiny_vars/log_var.numel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recons of samples from learned latent space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 36\n",
    "with torch.no_grad():\n",
    "    sampled_recons = model.sample(n_samples, model.device)\n",
    "    show_timgs(sampled_recons.detach())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect latent space\n",
    "For each x, first \n",
    "mu, logvar= model.encoder(x)\n",
    "z_samples = model.reparametrize(mu, logvar)\n",
    "\n",
    "- Compute pairwise distances between each image in  the (mini) batch of input images based on the \n",
    "Show $K$ number of nearest neighbors  analysis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Latent Space Traversal\n",
    "1. Linear traversal in a single dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen_dim = 0 # must be in range(latent_dim)\n",
    "fixed_vec = torch.randn((1, model.latent_dim-1))\n",
    "fixed_values = fixed_vec.repeat((n_samples,1))\n",
    "n_samples = 16\n",
    "zi_min, zi_max = -2,2\n",
    "varying = torch.linspace(zi_min, zi_max, n_samples).view((-1,1))\n",
    "\n",
    "varying.shape,fixed_values.shape\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_from(a_col:torch.Tensor, other_cols:torch.Tensor, ind):\n",
    "    \"\"\"\n",
    "    Make a tensor from a column vector and a matrx containing all the other columns\n",
    "    by inserting the `onc_column` at the final matrix's `ind`th column.\n",
    "    \"\"\"\n",
    "    assert a_\n",
    "    n_cols = 1 + \n",
    "    out = a_col.new_zeros(("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Misc experiments\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q: Does `torch`'s `dtype` conversion (eg. my_tensor.to(torch.float64)) keeps the new tensor attached to the original tensor's computational graph?\n",
    "Related:\n",
    "- `is_leaf`\n",
    "- `requires_grad`\n",
    "- `retain_grad`: See [doc](https://pytorch.org/docs/stable/autograd.html#torch.Tensor.is_leaf:~:text=Only%20leaf%20Tensors%20will%20have%20their,non%2Dleaf%20Tensors%2C%20you%20can%20use%20retain_grad().)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.ones(1, dtype=torch.float32, requires_grad=True)\n",
    "t2 = t.to(torch.float64)\n",
    "# t2.retain_grad()\n",
    "print(t.requires_grad, t2.requires_grad)\n",
    "print(t.is_leaf, t2.is_leaf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = 2*t2**3\n",
    "out.backward()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t2.grad, t.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, yes, the gradient flows via the tensor generated from the original tensor (`t`) with `.to` operation. Therefore, we conclude the tensor generated from `.to` method remains attached to the orignal tensor's computational graph and acts as a medium (ie. a non-leaf node) through which downstream operation's gradient can flow through to be accumulated at the original tensor `t`'s `.grad` attribute. \n",
    "\n",
    "Unless I want to look at the `.grad` of the derived tensor (`t2`), I don't need to call `.retain_grad()` method on `t2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:test]",
   "language": "python",
   "name": "conda-env-test-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
