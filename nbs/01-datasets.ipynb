{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize samples of data used for experiments\n",
    "- Dec 31, 2020\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,sys\n",
    "import re\n",
    "import math\n",
    "from datetime import datetime\n",
    "import time\n",
    "sys.dont_write_bytecode = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pathlib import Path\n",
    "from typing import List, Set, Dict, Tuple, Optional, Iterable, Mapping, Union, Callable, TypeVar\n",
    "\n",
    "from pprint import pprint\n",
    "from ipdb import set_trace as brpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from  torch.linalg import norm as tnorm\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.core.lightning import LightningModule\n",
    "from pytorch_lightning import loggers as pl_loggers\n",
    "from pytorch_lightning.tuner.tuning import Tuner\n",
    "\n",
    "\n",
    "# Select Visible GPU\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\" \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Path \n",
    "1. Add project root and src folders to `sys.path`\n",
    "2. Set DATA_ROOT to `maptile_v2` folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "this_nb_path = Path(os.getcwd())\n",
    "ROOT = this_nb_path.parent\n",
    "SRC = ROOT/'src'\n",
    "DATA_ROOT = Path(\"/data/hayley-old/maptiles_v2/\")\n",
    "paths2add = [this_nb_path, ROOT]\n",
    "\n",
    "print(\"Project root: \", str(ROOT))\n",
    "print('Src folder: ', str(SRC))\n",
    "print(\"This nb path: \", str(this_nb_path))\n",
    "\n",
    "\n",
    "for p in paths2add:\n",
    "    if str(p) not in sys.path:\n",
    "        sys.path.insert(0, str(p))\n",
    "        print(f\"\\n{str(p)} added to the path.\")\n",
    "# print(sys.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data.datasets.maptiles import MaptilesDataset, MapStyles\n",
    "from src.data.datamodules.maptiles_datamodule import MaptilesDataModule\n",
    "\n",
    "from src.data.transforms.transforms import Identity, Unnormalizer, LinearRescaler\n",
    "from src.data.transforms.functional import unnormalize\n",
    "\n",
    "from src.visualize.utils import show_timgs, show_batch\n",
    "from src.utils.misc import info\n",
    "from collections import OrderedDict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Digit datasets\n",
    "MNIST, MINSTM and USPS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- MNISTM\n",
    "    - original size of an image: (1, 16,16)\n",
    "    - labels: {0, ..., 9}\n",
    "- USPS\n",
    "    - original size of an image: (3, 28, 28)\n",
    "    - labels\" {0, ..., 9}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data.datasets.mnistm import MNISTM\n",
    "from torchvision.datasets import MNIST, USPS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNISTM Dataset\n",
    "bs = 16\n",
    "num_workers = 16\n",
    "pin_memory = True\n",
    "xforms = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    ])\n",
    "# target_xforms = \n",
    "mnistm_ds = MNISTM(ROOT/'data', \n",
    "          transform=xforms,\n",
    "          download=True)\n",
    "\n",
    "mnistm_dl = DataLoader(ds, batch_size=bs, shuffle=True, \n",
    "               num_workers=num_workers, pin_memory=pin_memory)\n",
    "\n",
    "\n",
    "x,y = next(iter(dl))\n",
    "info(x)\n",
    "info(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "show_timgs(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# USPS Dataset\n",
    "bs = 16\n",
    "num_workers = 16\n",
    "pin_memory = True\n",
    "xforms = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    ])\n",
    "# target_xforms = \n",
    "usps_ds = USPS(ROOT/'data', \n",
    "          transform=xforms,\n",
    "          download=True)\n",
    "\n",
    "usps_dl = DataLoader(ds, batch_size=bs, shuffle=True, \n",
    "               num_workers=num_workers, pin_memory=pin_memory)\n",
    "\n",
    "\n",
    "x,y = next(iter(dl))\n",
    "info(x)\n",
    "info(y)\n",
    "show_timgs(x, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsets = {\"mnistm\": mnistm_ds,\n",
    "         \"usps\": usps_ds}\n",
    "\n",
    "dls = {\"mnistm\": mnistm_dl,\n",
    "         \"usps\": usps_dl}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Compute channelwise mean and std of the images in the training/test splits\n",
    "- First for the MNISTM dataset whose images are RGB (ie. have 3 channels):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_channelwise_mean_std(\n",
    "            dset: Dataset,\n",
    "            n_channels: int) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Assume dset[i] returns a tuple of torch.Tensors (x,y)\n",
    "    and x is in range [0,1], of shape (n_channels, h, w).    \n",
    "    \"\"\"\n",
    "    channel_sum = torch.zeros(n_channels)\n",
    "    channel_squared_sum = torch.zeros(n_channels)\n",
    "    n_pixels = 0.\n",
    "    for i in range(len(dset)):\n",
    "        timg, _ = dset[i]\n",
    "        n_pixels += timg.shape[1] * timg.shape[2]\n",
    "        channel_sum += torch.sum(timg, dim=(1,2))\n",
    "        channel_squared_sum += torch.sum(timg ** 2, dim=(1,2))\n",
    "#         breakpoint()\n",
    "    channel_mean = channel_sum / n_pixels\n",
    "    channel_std = torch.sqrt(channel_squared_sum / n_pixels - channel_mean ** 2)\n",
    "    return channel_mean, channel_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"MNISTM\")\n",
    "for is_train in [True, False]:\n",
    "    print(\"Train: \", is_train)\n",
    "    ds  = MNISTM(ROOT/'data', \n",
    "                 train=is_train,\n",
    "                transform=transforms.ToTensor(),\n",
    "                  download=True)\n",
    "\n",
    "    print(\"\\tMean, std\")\n",
    "    print(\"\\t\", get_channelwise_mean_std(ds, 3))\n",
    "    \n",
    "# Train mean, std: (tensor([0.4639, 0.4676, 0.4199]), tensor([0.2534, 0.2380, 0.2618]))\n",
    "# Test mean, std: [0.4627, 0.4671, 0.4209]), tensor([0.2553, 0.2395, 0.2639]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Now, for the USPS dataset whose images are in grayscale (ie. have 1 channel):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"USPS\")\n",
    "for is_train in [True, False]:\n",
    "    print(\"Train: \", is_train)\n",
    "    ds  = USPS(ROOT/'data', \n",
    "             train=is_train,\n",
    "            transform=transforms.ToTensor(),\n",
    "          download=True)\n",
    "\n",
    "    print(\"\\tMean, std\")\n",
    "    print(\"\\t\", get_channelwise_mean_std(ds, 1))\n",
    "    \n",
    "#Train mean,std: tensor([0.2469]), tensor([0.2989] \n",
    "#Test mean,std: (tensor([0.2599]), tensor([0.3083]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## DataModule objects\n",
    "Test custom datamodules on each of the datasets above.\n",
    "1. MNIST-M\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data.datamodules import BaseDataModule, USPSDataModule, MNISTMDataModule, MNISTDataModule\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_dm = MNISTDataModule(data_root=ROOT/'data', \n",
    "                       in_shape=(1,32,32),\n",
    "                      batch_size=32)\n",
    "mnistm_dm = MNISTMDataModule(data_root=ROOT/'data', \n",
    "                       in_shape=(3, 32,32),\n",
    "                      batch_size=32)\n",
    "usps_dm = USPSDataModule(data_root=ROOT/'data', \n",
    "                       in_shape=(1,32,32),\n",
    "                      batch_size=32)\n",
    "\n",
    "for dm in [mnist_dm, mnistm_dm, usps_dm]:\n",
    "    print(dm.name)\n",
    "    dm.setup('fit')\n",
    "    cmap = 'gray' if dm.in_shape[0] < 3 else None\n",
    "    show_batch(dm, cmap=cmap, title=dm.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:test]",
   "language": "python",
   "name": "conda-env-test-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
