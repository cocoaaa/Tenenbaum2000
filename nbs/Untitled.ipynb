{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "coated-progressive",
   "metadata": {},
   "source": [
    "# Pyro's VAE: MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "constitutional-gazette",
   "metadata": {},
   "source": [
    "## Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "military-double",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "olympic-impression",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,sys\n",
    "import re\n",
    "import math\n",
    "from datetime import datetime\n",
    "import time\n",
    "sys.dont_write_bytecode = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "psychological-equilibrium",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.color import rgb2gray\n",
    "from skimage.transform import resize\n",
    "\n",
    "from pathlib import Path\n",
    "from typing import List, Set, Dict, Tuple, Optional, Iterable, Mapping, Union, Callable\n",
    "\n",
    "from pprint import pprint\n",
    "from ipdb import set_trace as brpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "classical-pottery",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from  torch.linalg import norm as tnorm\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.core.lightning import LightningModule\n",
    "from pytorch_lightning import loggers as pl_loggers\n",
    "# Select Visible GPU\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"2\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "electrical-practice",
   "metadata": {},
   "source": [
    "## Set Path \n",
    "1. Add project root and src folders to `sys.path`\n",
    "2. Set DATA_ROOT to `maptile_v2` folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "elementary-forestry",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root:  /data/hayley-old/Tenanbaum2000\n",
      "Src folder:  /data/hayley-old/Tenanbaum2000/src\n",
      "This nb path:  /data/hayley-old/Tenanbaum2000/nbs\n",
      "\n",
      "/data/hayley-old/Tenanbaum2000 added to the path.\n"
     ]
    }
   ],
   "source": [
    "this_nb_path = Path(os.getcwd())\n",
    "ROOT = this_nb_path.parent\n",
    "SRC = ROOT/'src'\n",
    "DATA_ROOT = Path(\"/data/hayley-old/maptiles_v2/\")\n",
    "paths2add = [this_nb_path, ROOT]\n",
    "\n",
    "print(\"Project root: \", str(ROOT))\n",
    "print('Src folder: ', str(SRC))\n",
    "print(\"This nb path: \", str(this_nb_path))\n",
    "\n",
    "\n",
    "for p in paths2add:\n",
    "    if str(p) not in sys.path:\n",
    "        sys.path.insert(0, str(p))\n",
    "        print(f\"\\n{str(p)} added to the path.\")\n",
    "        \n",
    "# print(sys.path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "identified-cinema",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from src.data.datasets.maptiles import Maptiles, MapStyles\n",
    "from src.data.datamodules.mnist_datamodule import MNISTDataModule\n",
    "from src.data.datamodules.maptiles_datamodule import MaptilesDataModule\n",
    "\n",
    "from src.models.plmodules.three_fcs import ThreeFCs\n",
    "from src.models.plmodules.vanilla_vae import VanillaVAE\n",
    "from src.models.plmodules.beta_vae import BetaVAE\n",
    "\n",
    "from src.visualize.utils import show_timgs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afraid-russian",
   "metadata": {},
   "source": [
    "## Define VAE (model) in Pyro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "substantial-pennsylvania",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision.datasets as dset\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "import pyro.contrib.examples.util  # patches torchvision\n",
    "from pyro.infer import SVI, Trace_ELBO\n",
    "from pyro.optim import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "informed-savannah",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert pyro.__version__.startswith('1.5.1')\n",
    "pyro.enable_validation(True)\n",
    "pyro.distributions.enable_validation(False)\n",
    "pyro.set_rng_seed(0)\n",
    "# Enable smoke test - run the notebook cells on CI.\n",
    "smoke_test = 'CI' in os.environ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "major-sharp",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for loading and batching MNIST dataset\n",
    "def setup_data_loaders(batch_size=128, use_cuda=False):\n",
    "    root = './data'\n",
    "    download = True\n",
    "    trans = transforms.ToTensor()\n",
    "    train_set = dset.MNIST(root=root, train=True, transform=trans,\n",
    "                           download=download)\n",
    "    test_set = dset.MNIST(root=root, train=False, transform=trans)\n",
    "\n",
    "    kwargs = {'num_workers': 1, 'pin_memory': use_cuda}\n",
    "    train_loader = torch.utils.data.DataLoader(dataset=train_set,\n",
    "        batch_size=batch_size, shuffle=True, **kwargs)\n",
    "    test_loader = torch.utils.data.DataLoader(dataset=test_set,\n",
    "        batch_size=batch_size, shuffle=False, **kwargs)\n",
    "    return train_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tracked-collins",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "amended-noise",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DM:  MNIST\n"
     ]
    }
   ],
   "source": [
    "# Instantiate MNIST Datamodule\n",
    "in_shape = (1,32,32)\n",
    "batch_size = 32\n",
    "dm = MNISTDataModule(data_root=ROOT/'data', \n",
    "                       in_shape=in_shape,\n",
    "                      batch_size=batch_size)\n",
    "dm.setup('fit')\n",
    "print(\"DM: \", dm.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "beneficial-stress",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the pl Module\n",
    "betas = [0.1 * 3**i for i in range(10)]\n",
    "# for kld_weight in [1.0]\n",
    "latent_dim = 10\n",
    "hidden_dims = [32,64,128,256]#,512]\n",
    "act_fn = nn.LeakyReLU()\n",
    "learning_rate = 3e-4\n",
    "kld_weight = betas[0]\n",
    "model = BetaVAE(\n",
    "    in_shape=in_shape, \n",
    "    latent_dim=latent_dim,\n",
    "    hidden_dims=hidden_dims,\n",
    "    learning_rate=learning_rate,\n",
    "    act_fn=act_fn,\n",
    "    kld_weight=kld_weight\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "confident-brooklyn",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Sequential(\n",
       "    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): LeakyReLU(negative_slope=0.01)\n",
       "  )\n",
       "  (1): Sequential(\n",
       "    (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): LeakyReLU(negative_slope=0.01)\n",
       "  )\n",
       "  (2): Sequential(\n",
       "    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): LeakyReLU(negative_slope=0.01)\n",
       "  )\n",
       "  (3): Sequential(\n",
       "    (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): LeakyReLU(negative_slope=0.01)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "apart-carry",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:test]",
   "language": "python",
   "name": "conda-env-test-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
