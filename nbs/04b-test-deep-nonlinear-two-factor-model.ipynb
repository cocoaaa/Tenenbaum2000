{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test: Deep, non-linear, two-factor model\n",
    "- Date: Dec 2, 2020\n",
    "\n",
    "## TODO:\n",
    "- [ ] Test ShallowSymBilinear (W tensor, A,B + non-linear (sigmoid))\n",
    "    - [ ] Run experiments and compare performances \n",
    "\n",
    "- [ ] Implement Residual learning framework for bilinear models\n",
    "- [ ] Test ResidualBilinear \n",
    "    - [ ] Single W layer + non-linear\n",
    "    - [ ] Two step residual learning: similar to ResNet\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A standard symmetric bilinear model in Tenanbaum2000 can be described as:\n",
    "$$y^{sc}_k = \\sum_{j} \\sum_{i} w_{ijk}a^s_{i}b^c_{j}$$, which has an equivalent vector form:\n",
    "\n",
    "$$\\mathbf{y}^{sc} = \\sum_{j} \\sum_{i} \\mathbf{W}_{ij}a^s_{i}b^c_{j}$$ where $\\mathbf{W}_{ij}$ is a matrix of size (i,j).\n",
    "\n",
    "This symmetric model has 2 types of model parameters:\n",
    "- content variable $b$ of length $J$\n",
    "- K number of matrix $W_{ij}$ of size $(I,J)$: total number of parameters of this 3Dim tensior $W$ is IxJxK.\n",
    "    - Basis vector interpretation (See Eqn. 2.3): Alternative way to view this interaction weight parameter W is to view as $I \\times J$ number of vectors $w_{ij}$, each of which has a length of $K$.\n",
    "      This vector $w_{ij}$ specifices \n",
    "      - If we want to look at how the ith component of a style vector a^s and the jth component of a content vector b^c interacts over the entire image/data point"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "# %reset out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,sys\n",
    "import re\n",
    "import math\n",
    "from datetime import datetime\n",
    "import time\n",
    "sys.dont_write_bytecode = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import joblib\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy as sp\n",
    "from skimage.color import rgb2gray\n",
    "from skimage.transform import resize\n",
    "\n",
    "from pprint import pprint\n",
    "from pathlib import Path\n",
    "from typing import List, Set, Dict, Tuple, Optional, Iterable, Mapping, Union, Callable\n",
    "\n",
    "from ipdb import set_trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import holoviews as hv\n",
    "# from holoviews import opts\n",
    "# hv.extension('bokeh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from  torch.linalg import norm as tnorm\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "this_nb_path = Path(os.getcwd())\n",
    "ROOT = this_nb_path.parent\n",
    "SRC = ROOT/'src'\n",
    "paths2add = [this_nb_path, ROOT, SRC]\n",
    "\n",
    "print(\"Project root: \", str(ROOT))\n",
    "print('Src folder: ', str(SRC))\n",
    "print(\"This nb path: \", str(this_nb_path))\n",
    "\n",
    "\n",
    "for p in paths2add:\n",
    "    if str(p) not in sys.path:\n",
    "        sys.path.insert(0, str(p))\n",
    "        print(str(p), \"added to the path\\n\")\n",
    "        \n",
    "# print(sys.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries from the source\n",
    "from src.models.SymBilinear import ShallowSymBilinear\n",
    "from src.utils.misc import info\n",
    "from src.data.transforms.functional import to_3dim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def now2str():\n",
    "    now = datetime.now()\n",
    "    now_str = now.strftime(\"%m_%d_%H:%M:%S\")\n",
    "    return now_str\n",
    "\n",
    "def info(arr, header=None):\n",
    "    if header is None:\n",
    "        header = \"=\"*30\n",
    "    print(header)\n",
    "    print(\"shape: \", arr.shape)\n",
    "    print(\"dtype: \", arr.dtype)\n",
    "    print(\"min, max: \", min(np.ravel(arr)), max(np.ravel(arr)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_3dim(X: torch.Tensor, target_size: Tuple[int,int,int], dtype=torch.float32)->torch.Tensor:\n",
    "    \"\"\"\n",
    "    Rearragne data matrix X of size (n_styles*dim_x, n_contents) \n",
    "    to (n_styles, n_contents, dim_x)\n",
    "    \n",
    "    Args: \n",
    "    - X: torch.Tensor of 2dim data matrix\n",
    "    - target_size: tuple of n_style, n_contents, dim_x\n",
    "    \"\"\"\n",
    "    assert X.ndim == 2\n",
    "    n_styles, n_contents, dim_x = target_size\n",
    "    assert X.shape[0] == n_styles * dim_x\n",
    "    assert X.shape[1] == n_contents\n",
    "\n",
    "    target = torch.zeros(target_size, dtype=X.dtype)\n",
    "    \n",
    "    for s in range(n_styles):\n",
    "        for c in range(n_contents):\n",
    "            img = X[s*dim_x: (s+1)*dim_x, c]\n",
    "            target[s,c] = img\n",
    "    return target.to(dtype)\n",
    "    \n",
    "        \n",
    "# def mse(out, target):\n",
    "#     \"\"\"\n",
    "#     Return a \n",
    "#     out: a minibatch of reconstructed images: (S,C,K)\n",
    "#     target: a minibatch of ground-truth images: (S,C,K)\n",
    "#     \"\"\"\n",
    "#     assert out.shape == target.shape\n",
    "#     n_styles, n_contents, dim_x = out.shape\n",
    "#     n_samples = n_stlyes * n_contents\n",
    "#     return nn.MSELoss()\n",
    "\n",
    "loss_fn = nn.MSELoss()   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "styles.shape,contents.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contents.shape[-2:] == (dim_content,1), styles.shape[-2:] == (1,dim_style)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TFModel(styles, contents, W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, p in model.named_parameters():\n",
    "    print(f\"{name}: {p.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model(0,0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = model()\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Restore data matrix variable X as saved from the notebook \"02\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r X\n",
    "%store -r TARGET_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test create_target\n",
    "def test_create_target():\n",
    "    pass\n",
    "\n",
    "# 3 styles, 9 contents, x_dim = np.prod(TARGET_SIZE), TARGET_SIZE = (64,64,3) \n",
    "sx, n_contents = X.shape\n",
    "dim_x = np.prod(TARGET_SIZE)\n",
    "img_size = TARGET_SIZE\n",
    "n_styles = int(sx/dim_x)\n",
    "print(X.shape)\n",
    "print(\"n_styles, n_contents, dim_x: \", n_styles, n_contents, dim_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_3d = to_3dim(X, (n_styles, n_contents, dim_x) )\n",
    "X_3d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize(X, n_styles, n_contents, img_size);\n",
    "# visualize(X_3d, n_styles, n_contents, img_size);\n",
    "visualize(out.detach(), n_styles, n_contents, img_size, \n",
    "          normalize=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compiled training specs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mkdir(p: Path, parents=True):\n",
    "    if not p.exists():\n",
    "        p.mkdir(parents=parents)\n",
    "        print(\"Created: \", p)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_exp_name(hyperparams):\n",
    "    pass\n",
    "\n",
    "# Hyperparameters\n",
    "n_styles, dim_style = 3, 3\n",
    "n_contents, dim_content = 9, 4\n",
    "img_size = (64,64,3)\n",
    "dim_x = np.prod(img_size)\n",
    "\n",
    "# Define model\n",
    "styles = torch.randn((n_styles, 1,1, dim_style)) # A: each row is a style vector\n",
    "W = torch.randn((dim_x, dim_style, dim_content))\n",
    "contents = torch.randn((n_contents, 1,1, dim_content,1)) # B: each column is a content vector\n",
    "\n",
    "model = TFModel(styles, contents, W)\n",
    "# model.show_params()\n",
    "\n",
    "# Gradient computation\n",
    "## learn_rate depending on the type of reduction on computing the MSELoss\n",
    "lrs = {'mean': 1e-2,\n",
    "      'sum': 1e-6}\n",
    "\n",
    "\n",
    "# Specify loss function and learning rate\n",
    "reduction = 'mean'\n",
    "lr = lrs[reduction]\n",
    "lr_W = lr*30\n",
    "# Optimizer\n",
    "optim_params = [\n",
    "    {'params': [model.styles, model.contents]},\n",
    "    {'params': [model.W], 'lr': lr_W}\n",
    "]\n",
    "optimizer = optim.Adam(optim_params, lr=lr)\n",
    "\n",
    "\n",
    "# Training configs\n",
    "max_epoches = 100\n",
    "print_every = 10\n",
    "show_every = 30\n",
    "\n",
    "# data\n",
    "target = to_3dim(X, (n_styles, n_contents, dim_x))\n",
    "\n",
    "# Start training\n",
    "start = time.time()\n",
    "losses = []\n",
    "for ep in range(max_epoches):\n",
    "    # Compute loss, and compute partial derivatives wrt each parameters, which will be stored \n",
    "    # in each parameter (tensor)'s `.grad` property\n",
    "    out = model()\n",
    "    loss = nn.MSELoss(reduction=reduction)(out, target) #per-dim of x (pixel)\n",
    "    \n",
    "    # Make sure all the `.grad`s of the model parameters are zero \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    losses.append(loss.item())\n",
    "\n",
    "    \n",
    "    # Check if the parameters are changing before/after the gradient step\n",
    "    model.cache_params()\n",
    "    # Update the parameter values using the current partial derivatives based on the current loss\n",
    "    optimizer.step()\n",
    "    model.all_params_changed()\n",
    "   \n",
    "#     set_trace()\n",
    "    \n",
    "    # Log\n",
    "    with torch.no_grad():\n",
    "        if (ep+1)%print_every == 0:\n",
    "            print(f\"Ep {ep}: {loss.item()}\")\n",
    "            for n,p in model.named_parameters():\n",
    "                print(n)\n",
    "                print('\\t', tnorm(p), tnorm(p.grad))\n",
    "        if (ep+1)%show_every == 0:\n",
    "            model.show_params()\n",
    "            visualize(out, n_styles, n_contents, img_size, normalize=True);\n",
    "print(f\"Took {time.time() - start} sec. Loss: {losses[-1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment name\n",
    "result_dir = Path(\"../results/batch_bilinear/{model.descr()}\")\n",
    "mkdir(result_dir)\n",
    "exp_descr = f\"reduction:{reduction}_lr:{lr}_lrW:{lr_W}_ep:{ep}\"\n",
    "\n",
    "# save model parameters\n",
    "# save last reconstructions\n",
    "f_params = model.show_params()\n",
    "f_params.savefig(result_dir/f\"params_{exp_descr}\")\n",
    "with torch.no_grad():\n",
    "    out = model()\n",
    "    f_out = visualize(out, n_styles, n_contents, img_size, normalize=True);\n",
    "    f_out.savefig(result_dir/f\"xhat_{exp_descr}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(losses)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:torch2]",
   "language": "python",
   "name": "conda-env-torch2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
