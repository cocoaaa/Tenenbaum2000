{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,sys\n",
    "import re\n",
    "import math\n",
    "from datetime import datetime\n",
    "import time\n",
    "sys.dont_write_bytecode = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.color import rgb2gray\n",
    "from skimage.transform import resize\n",
    "\n",
    "from pathlib import Path\n",
    "from typing import List, Set, Dict, Tuple, Optional, Iterable, Mapping, Union, Callable\n",
    "\n",
    "from pprint import pprint\n",
    "from ipdb import set_trace as brpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from  torch.linalg import norm as tnorm\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.core.lightning import LightningModule\n",
    "from pytorch_lightning import loggers as pl_loggers\n",
    "\n",
    "import ray\n",
    "# Select Visible GPU\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"2\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Path \n",
    "1. Add project root and src folders to `sys.path`\n",
    "2. Set DATA_ROOT to `maptile_v2` folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "this_nb_path = Path(os.getcwd())\n",
    "ROOT = this_nb_path.parent\n",
    "SRC = ROOT/'src'\n",
    "DATA_ROOT = Path(\"/data/hayley-old/maptiles_v2/\")\n",
    "paths2add = [this_nb_path, ROOT]\n",
    "\n",
    "print(\"Project root: \", str(ROOT))\n",
    "print('Src folder: ', str(SRC))\n",
    "print(\"This nb path: \", str(this_nb_path))\n",
    "\n",
    "\n",
    "for p in paths2add:\n",
    "    if str(p) not in sys.path:\n",
    "        sys.path.insert(0, str(p))\n",
    "        print(f\"\\n{str(p)} added to the path.\")\n",
    "        \n",
    "# print(sys.path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from src.data.datasets.maptiles import Maptiles, MapStyles\n",
    "# from src.data.datamodules.mnist_datamodule import MNISTDataModule\n",
    "# from src.data.datamodules.maptiles_datamodule import MaptilesDataModule\n",
    "from src.data.datamodules.multisource_maptiles_datamodule import MultiMaptilesDataModule\n",
    "\n",
    "\n",
    "# from src.models.plmodules.three_fcs import ThreeFCs\n",
    "# from src.models.plmodules.vanilla_vae import VanillaVAE\n",
    "# from src.models.plmodules.beta_vae import BetaVAE\n",
    "from src.models.plmodules.bilatent_vae import BiVAE\n",
    "\n",
    "from src.visualize.utils import show_timgs, show_npimgs\n",
    "from src.utils.misc import info, get_next_version_path, n_iter_per_epoch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start experiment \n",
    "Given a maptile, predict its style as one of OSM, CartoVoyager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Instantiate MNIST Datamodule\n",
    "# in_shape = (1,32,32)\n",
    "# batch_size = 32\n",
    "# dm = MNISTDataModule(data_root=ROOT/'data', \n",
    "#                        in_shape=in_shape,\n",
    "#                       batch_size=batch_size)\n",
    "# dm.setup('fit')\n",
    "# print(\"DM: \", dm.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate Multisource Maptiles DataModule\n",
    "all_cities = ['la', 'charlotte', 'vegas', 'boston', 'paris', \\\n",
    "              'amsterdam', 'shanghai', 'seoul', 'chicago', 'manhattan', \\\n",
    "             'berlin', 'montreal', 'rome']\n",
    "\n",
    "data_root = Path(\"/data/hayley-old/maptiles_v2/\")\n",
    "cities = all_cities # ['berlin', 'rome', 'la', 'amsterdam', 'seoul'] #['paris']\n",
    "styles =['StamenWatercolor']#['StamenTonerBackground','OSMDefault', 'CartoVoyagerNoLabels']#'StamenWatercolor']#, 'StamenTonerLines']\n",
    "zooms = ['14']\n",
    "in_shape = (3, 64, 64)\n",
    "batch_size = 32\n",
    "print('cities: ', cities)\n",
    "print('styes: ', styles)\n",
    "dm = MultiMaptilesDataModule(\n",
    "    data_root=data_root,\n",
    "    cities=cities,\n",
    "    styles=styles,\n",
    "    zooms=zooms,\n",
    "    in_shape=in_shape,\n",
    "    batch_size=batch_size,\n",
    ")\n",
    "dm.setup('fit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Country name and tile extent (in Kilometers) from tile numbers and zoom (x,y,z)\n",
    "- Updated: Mar 8, 2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils.geo import getTileExtent, getCountryFromTile, getGeoFromTile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn = \"/data/hayley-old/maptiles_v2/paris/StamenWatercolor/14/8301_5639_14.png\"\n",
    "# img = plt.imread(fn)\n",
    "img = plt.imread(fn, format='jpg')\n",
    "\n",
    "info(img)\n",
    "plt.imshow(img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fn = \"/data/hayley-old/maptiles_v2/paris/StamenTonerBackground/14/8301_5638_14.png\"\n",
    "img = plt.imread(fn, format='jpg')\n",
    "info(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paris_dir = Path(\"/data/hayley-old/maptiles_v2/paris\")\n",
    "zoom='14'\n",
    "paris_samples = {}\n",
    "\n",
    "idx = np.random.randint(100)\n",
    "for style_dir in paris_dir.iterdir():\n",
    "    style = style_dir.stem\n",
    "    zoom_dir = style_dir/zoom\n",
    "    for i, p in enumerate(zoom_dir.iterdir()):\n",
    "        if p.is_file() and i == idx:\n",
    "            try:\n",
    "                img = plt.imread(p)\n",
    "            except SyntaxError:\n",
    "                img = plt.imread(p, format='jpg')\n",
    "            paris_samples[style] = img\n",
    "            print(style)\n",
    "            info(img)\n",
    "            \n",
    "            # xyz: get tile extent and country\n",
    "            x,y,z = map(int, p.stem.split('_'))\n",
    "            country = getCountryFromTile(x,y,z)\n",
    "            size_y, size_x = getTileExtent(x,y,z)\n",
    "            \n",
    "            print('x, y, z: ', x,y,z)\n",
    "            print('lat_deg, lng_deg: ', getGeoFromTile(x,y,z))\n",
    "            print(country)\n",
    "            print('tile size in meters (y,x dir): ',size_y, size_x)\n",
    "            print()\n",
    "\n",
    "            break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show random maptiles\n",
    "# Mar 12, 2021\n",
    "paris_dir = Path(\"/data/hayley-old/maptiles_v2/paris\")\n",
    "zoom='14'\n",
    "paris_samples = {}\n",
    "\n",
    "styles2show = ['StamenTonerBackground', 'StamenWatercolor', 'OSMDefault']\n",
    "n_samples = 10\n",
    "locations = [] # list of (lat_deg, lng_deg)\n",
    "imgs = []\n",
    "extents = [] # list of the physical area extent covered by the maptile; in meters (size_y, size_x)\n",
    "for style_dir in paris_dir.iterdir():\n",
    "    style = style_dir.stem\n",
    "    zoom_dir = style_dir/zoom\n",
    "    \n",
    "    print(f'style: {style}')\n",
    "    if not style in styles2show:\n",
    "        print(f'skipping {style}...')\n",
    "        continue\n",
    "        \n",
    "    img_fns = [p for p in zoom_dir.iterdir() if p.is_file()]\n",
    "    n_imgs = len(img_fns)\n",
    "    inds = np.random.randint(n_imgs, size=n_samples)\n",
    "    for ind in inds:\n",
    "        p = img_fns[ind]\n",
    "        try:\n",
    "            img = plt.imread(p)\n",
    "        except SyntaxError:\n",
    "            img = plt.imread(p, format='jpg')\n",
    "        imgs.append(img)\n",
    "\n",
    "        # xyz: get tile extent and country\n",
    "        x,y,z = map(int, p.stem.split('_'))\n",
    "        country = getCountryFromTile(x,y,z)\n",
    "        size_y, size_x = getTileExtent(x,y,z)\n",
    "        lat_deg, lng_deg =  getGeoFromTile(x,y,z)\n",
    "        locations.append((lat_deg, lng_deg))\n",
    "        \n",
    "        # Plot and Printout\n",
    "        info(img)\n",
    "        print('x, y, z: ', x,y,z)\n",
    "        print('lat_deg, lng_deg: ', lat_deg, lng_deg)\n",
    "        print(country)\n",
    "        print('tile size in meters (y,x dir): ',size_y, size_x)\n",
    "#         plt.imshow(img)\n",
    "#         plt.show()\n",
    "        print()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def round_lat_lng(loc, decimals=2) -> Tuple[float]:\n",
    "    \"loc (Tuple[float]): (lat_deg, lng_deg)\"\n",
    "    return np.round(loc[0], decimals), np.round(loc[1], decimals)\n",
    "\n",
    "\n",
    "titles = list(map(round_lat_lng, locations))\n",
    "show_npimgs(imgs, titles=titles);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Road network queries from OSM using OSMnx\n",
    "- Verify the road networks look similar to the ones in the maptiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_locs = np.array(locations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_locs = pd.DataFrame(np_locs, columns=['lat', 'lng'])\n",
    "df_locs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "city = 'paris'\n",
    "df_locs.to_pickle(ROOT/f'cache/sample_locations_{city}.pkl')\n",
    "df_locs.to_csv(ROOT/f'cache/sample_locations_{city}.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!conda list | grep joblib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate Multisource Maptiles DataModule\n",
    "all_cities = ['la', 'charlotte', 'vegas', 'boston', 'paris', \\\n",
    "              'amsterdam', 'shanghai', 'seoul', 'chicago', 'manhattan', \\\n",
    "             'berlin', 'montreal', 'rome']\n",
    "\n",
    "data_root = Path(\"/data/hayley-old/maptiles_v2/\")\n",
    "cities = all_cities # ['berlin', 'rome', 'la', 'amsterdam', 'seoul'] #['paris']\n",
    "styles =['StamenTonerBackground','OSMDefault', 'CartoVoyagerNoLabels']#'StamenWatercolor']#, 'StamenTonerLines']\n",
    "zooms = ['14']\n",
    "in_shape = (3, 64, 64)\n",
    "batch_size = 32\n",
    "print('cities: ', cities)\n",
    "print('styes: ', styles)\n",
    "\n",
    "start = time.time()\n",
    "dm = MultiMaptilesDataModule(\n",
    "    data_root=data_root,\n",
    "    cities=cities,\n",
    "    styles=styles,\n",
    "    zooms=zooms,\n",
    "    in_shape=in_shape,\n",
    "    batch_size=batch_size,\n",
    ")\n",
    "dm.setup('fit')\n",
    "\n",
    "print('Took: ', time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the processed cities-styles's filenames for another init of the same dataset in later experiments\n",
    "from collections import defaultdict\n",
    "cache = defaultdict(dict)\n",
    "\n",
    "city_str = '-'.join(sorted(cities))\n",
    "style_str = '-'.join(styles)\n",
    "cache[city_str][style_str] = dm.df_fns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cache"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save dataframe of filenames for this Datamodule (entire DM, ie. including both train_ds and val_ds (and test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir = ROOT/f'cache/{city_str}'\n",
    "if not out_dir.exists:\n",
    "    out_dir.mkdir(parents=True)\n",
    "    print('Created: ', out_dir)\n",
    "fn = f'df_fns_{style_str}.pkl'\n",
    "\n",
    "joblib.dump(dm.df_fns, out_dir/fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test if we can load the cached df_fns and create the same  train_ds and val_ds\n",
    "df_fns = joblib.load(out_dir/fn)\n",
    "print(len(df_fns))\n",
    "assert (df_fns.equals(dm.df_fns))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "dm2 =  MultiMaptilesDataModule(\n",
    "    df_fns = df_fns,\n",
    "    data_root=data_root,\n",
    "    cities=cities,\n",
    "    styles=styles,\n",
    "    zooms=zooms,\n",
    "    in_shape=in_shape,\n",
    "    batch_size=batch_size,\n",
    ")\n",
    "dm2.setup('fit')\n",
    "print('=== Using cached df_fns ===')\n",
    "print('DM init took: ', time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Pickle this datamodule\n",
    "# import joblib\n",
    "# nb_name = '16-a'\n",
    "# joblib.dump(dm, ROOT/'cache'/f'dm_{nb_name}.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('train size: ', len(dm.train_ds))\n",
    "# show a batch\n",
    "dl = dm.train_dataloader()\n",
    "batch = next(iter(dl))\n",
    "x, label_c, label_s = dm.unpack(batch)\n",
    "info(x)\n",
    "show_timgs(x, titles=label_s.tolist(), cmap='gray' if in_shape[0]==1 else None)\n",
    "print(label_c)\n",
    "print(label_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the pl Module\n",
    "from src.models.plmodules.bilatent_vae import BiVAE\n",
    "\n",
    "# betas = [0.1 * 3**i for i in range(10)]\n",
    "# for kld_weight in [1.0]\n",
    "n_styles = len(styles)\n",
    "latent_dim = 10\n",
    "hidden_dims = [32, 64, 128, 256] #,512]\n",
    "adversary_dims = [32,32,32]\n",
    "act_fn = nn.LeakyReLU()\n",
    "learning_rate = 3e-4\n",
    "\n",
    "is_contrasive = True\n",
    "kld_weight = 1.0 # vae_loss = recon_loss + kld_weight * kld_weight; betas[0];\n",
    "adv_loss_weight = 15. # loss = vae_loss + adv_loss_weight * adv_loss\n",
    "\n",
    "# enc_type = 'resnet'\n",
    "enc_type = 'conv'\n",
    "\n",
    "# dec_type = 'conv'\n",
    "dec_type = 'resnet'\n",
    "\n",
    "if enc_type == 'resnet':\n",
    "    hidden_dims = [32, 32, 64, 128, 256]\n",
    "\n",
    "model = BiVAE(\n",
    "    in_shape=in_shape, \n",
    "    n_styles=n_styles,\n",
    "    latent_dim=latent_dim,\n",
    "    hidden_dims=hidden_dims,\n",
    "    adversary_dims=adversary_dims,\n",
    "    learning_rate=learning_rate,\n",
    "    act_fn=act_fn,\n",
    "    is_contrasive=is_contrasive,\n",
    "    kld_weight=kld_weight,\n",
    "    adv_loss_weight=adv_loss_weight,\n",
    "    enc_type=enc_type,\n",
    "    dec_type=dec_type,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate a PL `Trainer` object\n",
    "# Start the experiment\n",
    "max_epochs = 200\n",
    "exp_name = f'{model.name}_{dm.name}'\n",
    "tb_logger = pl_loggers.TensorBoardLogger(save_dir=f'{ROOT}/temp-logs', \n",
    "                                         name=exp_name,\n",
    "                                         log_graph=False,\n",
    "                                        default_hp_metric=False)\n",
    "print(\"Log dir: \", tb_logger.log_dir)\n",
    "\n",
    "log_dir = Path(tb_logger.log_dir)\n",
    "if not log_dir.exists():\n",
    "    log_dir.mkdir(parents=True)\n",
    "    print(\"\\nCreated: \", log_dir)\n",
    "    \n",
    "\n",
    "# Log computational graph\n",
    "# model_wrapper = ModelWrapper(model)\n",
    "# tb_logger.experiment.add_graph(model_wrapper, model.example_input_array.to(model.device))\n",
    "# tb_logger.log_graph(model)\n",
    "\n",
    "trainer_config = {\n",
    "    'gpus':1,\n",
    "    'max_epochs': max_epochs,\n",
    "    'progress_bar_refresh_rate':0,\n",
    "    'terminate_on_nan':True,\n",
    "    'check_val_every_n_epoch':10,\n",
    "    'logger':tb_logger,\n",
    "#     'callbacks':callbacks,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ray - Tune: efficient hyperparameter turning of DL experiments with distributed execution engine (in Python)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ray.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training is logged to (on March 1st, 2021)\n",
    "\n",
    "Log dir:  /data/hayley-old/Tenanbaum2000/temp-logs/BiVAE-C-conv-resnet-1.0-15.0_Maptiles_la-charlotte-vegas-boston-paris-amsterdam-shanghai-seoul-chicago-manhattan-berlin-montreal-rome_CartoVoyagerNoLabels-OSMDefault-StamenTonerBackground_14/version_0\n",
    "Created:  /data/hayley-old/Tenanbaum2000/temp-logs/BiVAE-C-conv-resnet-1.0-15.0_Maptiles_la-charlotte-vegas-boston-paris-amsterdam-shanghai-seoul-chicago-manhattan-berlin-montreal-rome_CartoVoyagerNoLabels-OSMDefault-StamenTonerBackground_14/version_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer = pl.Trainer(fast_dev_run=3)\n",
    "trainer = pl.Trainer(**trainer_config)\n",
    "# trainer.tune(model=model, datamodule=dm)\n",
    "print(\"\\nMetrics: \", trainer.callback_metrics.keys())# todo: delete\n",
    "\n",
    "# Fit model\n",
    "trainer.fit(model, dm)\n",
    "print(f\"Finished at ep {trainer.current_epoch, trainer.batch_idx}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.current_epoch, model.logger.log_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Log  hparmeters and `best_score` to tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hparams = model.hparams.copy()\n",
    "hparams.update(dm.hparams)\n",
    "best_score = trainer.checkpoint_callback.best_model_score.item()\n",
    "metrics = {'hparam/best_score': best_score} #todo: define a metric and use it here\n",
    "pprint(hparams)\n",
    "pprint(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use pl.Logger's method \"log_hyperparameters\" which handles the \n",
    "# hparams' element's formats to be suitable for Tensorboard logging\n",
    "# See: \n",
    "# https://sourcegraph.com/github.com/PyTorchLightning/pytorch-lightning@be3e8701cebfc59bec97d0c7717bb5e52afc665e/-/blob/pytorch_lightning/loggers/tensorboard.py#explorer:~:text=def%20log_hyperparams\n",
    "best_score = trainer.checkpoint_callback.best_model_score.item()\n",
    "metrics = {'hparam/best_score': best_score} #todo: define a metric and use it here\n",
    "trainer.logger.log_hyperparams(hparams, metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "# Evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models.plmodules.utils import get_best_ckpt, load_model, load_best_model\n",
    "from pytorch_lightning.utilities.cloud_io import load as pl_load\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load best model recorded during the training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_path = get_best_ckpt(model, verbose=True)\n",
    "ckpt = pl_load(ckpt_path, map_location=lambda storage, loc: storage)  # dict object\n",
    "print(ckpt['epoch'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load bestmodel\n",
    "model.load_state_dict(ckpt['state_dict'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": "true"
   },
   "source": [
    "## Reconstruction\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "def show_recon(model: BiVAE, \n",
    "               tb_writer: SummaryWriter=None,\n",
    "               global_step:int=0,\n",
    "               unnorm:bool=True, \n",
    "               to_show:bool=True, \n",
    "               verbose:bool=False):\n",
    "    model.eval()\n",
    "    dm = model.trainer.datamodule\n",
    "    cmap = 'gray' if dm.size()[0] ==1 else None\n",
    "    train_mean, train_std = dm.train_mean, dm.train_std\n",
    "    with torch.no_grad():\n",
    "        for mode in ['train', 'val']:\n",
    "            dl = getattr(model, f\"{mode}_dataloader\")()\n",
    "            batch = next(iter(dl))\n",
    "            \n",
    "            x = batch['img']\n",
    "#             label_c = batch['digit']  # digit/content label (int) -- currently not used\n",
    "#             label_s = batch['color']\n",
    "            x = x.to(model.device)\n",
    "            x_recon = model.generate(x)\n",
    "            \n",
    "            # Move to cpu for visualization\n",
    "            x = x.cpu()\n",
    "            x_recon = x_recon.cpu()\n",
    "            \n",
    "            if verbose: \n",
    "                info(x, f\"{mode}_x\")\n",
    "                info(x_recon, f\"{mode}_x_recon\")\n",
    "                \n",
    "            if unnorm:\n",
    "                x_unnormed = unnormalize(x, train_mean, train_std)\n",
    "                x_recon_unnormed = unnormalize(x_recon, train_mean, train_std)\n",
    "                if verbose:\n",
    "                    print(\"===After unnormalize===\")\n",
    "                    info(x_unnormed, f\"{mode}_x_unnormed\")\n",
    "                    info(x_recon_unnormed, f\"{mode}_x_recon_unnormed\")\n",
    "                    \n",
    "            if to_show:\n",
    "                _x = x_unnormed if unnorm else x\n",
    "                _x_recon = x_recon_unnormed if unnorm else x_recon\n",
    "                show_timgs(_x, title=f\"Input: {mode}\", cmap=cmap)\n",
    "#                 show_timgs(_x_recon, title=f\"Recon: {mode}\", cmap=cmap)\n",
    "                show_timgs(LinearRescaler()(_x_recon), title=f\"Recon(linearized): {mode}\", cmap=cmap)\n",
    "\n",
    "            # Log input-recon grid to TB\n",
    "            if tb_writer is not None:\n",
    "                input_grid = torchvision.utils.make_grid(x_unnormed) # (C, gridh, gridw)\n",
    "                recon_grid = torchvision.utils.make_grid(x_recon_unnormed) # (C, gridh, gridw)\n",
    "                normed_recon_grid = torchvision.utils.make_grid(LinearRescaler()(x_recon_unnormed))\n",
    "                \n",
    "                grid = torch.cat([input_grid, normed_recon_grid], dim=-1) #inputs | recons\n",
    "                tb_writer.add_image(f\"{mode}/recons\", grid, global_step=global_step)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_recon(model, tb_logger.experiment, global_step=1, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:test]",
   "language": "python",
   "name": "conda-env-test-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
