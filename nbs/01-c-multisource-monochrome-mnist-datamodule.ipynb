{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a Multi-source datamodule for MNIST\n",
    "- Jan 6, 2021\n",
    "\n",
    "Each \"style\" of monochrome-mnist dataset puts a different color for the digit pixels.\n",
    "This notebooks shows \n",
    "\n",
    "- how we can create each of the datasets so that it outputs a consistent data sample\n",
    "at each call for the `__getitem__` method (eg. via indexing `myDataset[item_idx]`)\n",
    "\n",
    "- how to create a single dataset that outputs a datapoint from multiple datasets\n",
    "in a balanced way, ie. sampling as uniformly as possible to sample from any one of the \n",
    "datasets: \n",
    "\n",
    "Let's say we have 3 datasets, ds0, ds1, ds2, each of which contains n0, n1, n2 datapoints/observations\n",
    "respectively. Currently the implementation of `ConcatDataset` in `pytorch` samples a datapoint x from \n",
    "a single datasets d = [ds0, ds1, ds2] under a uniform distribution: p(x) = 1/(n0+n1+n2). Consequently, \n",
    "this \"uniform\" distribution puts a uniform probability mass on each datasample in the concatenated dataset, \n",
    "but the probability distribution of a sample coming from each dataset, say $\\pi = [\\pi_0, \\pi_1, \\pi_2]$ is not uniform, but rather a ratio of the number of samples, ie. $[n_0/n, n_1/n, n_2/n]$ where $n = n_0+n_1+n_2$.  \n",
    "If we want $\\pi$ to be a uniform distribution of selected source dataset, we \n",
    "could first compute the ratio of the dataset sizes, and input weighted number of datasets when creating \n",
    "the final, single dataset (of multiple sources).\n",
    "\n",
    "We will demonstrate how to use the ratio of dataset sizes to create a single, multi-source dataset from multiple datasources, so that the final, multi-course dataset outputs a datapoint, uniformly from any consitutent data source.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,sys\n",
    "import re\n",
    "import math\n",
    "from datetime import datetime\n",
    "import time\n",
    "sys.dont_write_bytecode = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pathlib import Path\n",
    "from typing import Any, List, Set, Dict, Tuple, Optional, Iterable, Mapping, Union, Callable, TypeVar\n",
    "\n",
    "from pprint import pprint\n",
    "from ipdb import set_trace as brpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, ConcatDataset,random_split\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.core.lightning import LightningModule\n",
    "from pytorch_lightning import loggers as pl_loggers\n",
    "\n",
    "\n",
    "# Select Visible GPU\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\" \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Path \n",
    "1. Add project root and src folders to `sys.path`\n",
    "2. Set DATA_ROOT to `maptile_v2` folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "this_nb_path = Path(os.getcwd())\n",
    "ROOT = this_nb_path.parent\n",
    "SRC = ROOT/'src'\n",
    "DATA_ROOT = Path(\"/data/hayley-old/maptiles_v2/\")\n",
    "paths2add = [this_nb_path, ROOT]\n",
    "\n",
    "print(\"Project root: \", str(ROOT))\n",
    "print('Src folder: ', str(SRC))\n",
    "print(\"This nb path: \", str(this_nb_path))\n",
    "\n",
    "\n",
    "for p in paths2add:\n",
    "    if str(p) not in sys.path:\n",
    "        sys.path.insert(0, str(p))\n",
    "        print(f\"\\n{str(p)} added to the path.\")\n",
    "# print(sys.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data.datamodules.maptiles_datamodule import MaptilesDataModule\n",
    "\n",
    "from src.visualize.utils import show_timg, show_timgs, show_batch, make_grid_from_tensors\n",
    "from src.utils.misc import info\n",
    "from collections import OrderedDict, defaultdict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create MonoMNIST datasets with proper `transforms`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A MonoMNIST dataset outputs a tuple of "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data.datasets.mono_mnist import MonoMNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mono_dir = ROOT/'data/Mono-MNIST'\n",
    "GrayMNIST = MonoMNIST(data_root=ROOT/'data/Mono-MNIST',\n",
    "                      color='gray',\n",
    "                      train=True)\n",
    "\n",
    "RedMNIST = MonoMNIST(data_root=ROOT/'data/Mono-MNIST',\n",
    "                    color='red',\n",
    "                    train=True)\n",
    "GreenMNIST = MonoMNIST(data_root=ROOT/'data/Mono-MNIST',\n",
    "                    color='green',\n",
    "                      train=True)\n",
    "BlueMNIST = MonoMNIST(data_root=ROOT/'data/Mono-MNIST',\n",
    "                    color='blue',\n",
    "                     train=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ds in [GrayMNIST, RedMNIST, GreenMNIST, BlueMNIST]:\n",
    "    print(f\"{ds.name}: {len(ds)}\")\n",
    "    for i in range(3):\n",
    "        x,y = ds[i]\n",
    "        if i == 0:\n",
    "            info(x, \"===x===\")\n",
    "            print(y)\n",
    "#         show_timg(x)\n",
    "#         plt.title(y)\n",
    "#         plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = RedMNIST\n",
    "dl = DataLoader(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = next(iter(dl))\n",
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test MonoDatamodule for each color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data.datamodules import MonoMNISTDataModule\n",
    "in_shape = (3,32,32)\n",
    "batch_size=16\n",
    "color = 'red'\n",
    "\n",
    "dm = MonoMNISTDataModule(\n",
    "    data_root=mono_dir,\n",
    "    color=color,\n",
    "    seed=123,\n",
    "    in_shape=in_shape,\n",
    "    batch_size=batch_size\n",
    ")\n",
    "dm.setup('fit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for color in ['gray', 'red', 'green', 'blue']:\n",
    "    dm = MonoMNISTDataModule(\n",
    "        data_root=Path('/data/hayley-old/Tenanbaum2000/data/Mono-MNIST/'),\n",
    "        color=color,\n",
    "        seed=123,\n",
    "        in_shape=in_shape,\n",
    "        batch_size=batch_size\n",
    "    )\n",
    "    dm.setup('fit')\n",
    "    show_batch(dm, cmap='gray' if color=='gray' else None) \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Multi-source monochrome dataset \n",
    "by concatenating multipel MonoMNIST datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsets = [GrayMNIST, RedMNIST, GreenMNIST, BlueMNIST]\n",
    "print(\"===Num. of observations===\")\n",
    "print([len(ds) for ds in dsets])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ConcatDataset(dsets)\n",
    "ordered_dl = DataLoader(ds, batch_size=32, shuffle=False)\n",
    "shuffled_dl = DataLoader(ds, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dl in [ordered_dl, shuffled_dl]:\n",
    "    x,y = next(iter(dl))\n",
    "    show_timgs(x)\n",
    "    print(y)\n",
    "    print(\"===\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note:\n",
    "\n",
    "- In the batch from the `ordered_dl`, we see all images of digit_id 5 because that is how each Monochrome dataset is created (ie. appending all images of 5, then another digit_id, etc).\n",
    "- The ordered_dl iterates over all images in the first dataset (ie. GrayMNIST) and then iterate over the next datasets in order (because the DataLoader is created with `shuffle=False`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, we can create a multi-source dataset with two-styles as below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsets = [RedMNIST, GreenMNIST] #[GrayMNIST, RedMNIST, GreenMNIST, BlueMNIST]\n",
    "print(\"===Num. of observations===\")\n",
    "print([len(ds) for ds in dsets])\n",
    "\n",
    "# Create a multi-source dataset\n",
    "ds = ConcatDataset(dsets)\n",
    "\n",
    "# DataLoader\n",
    "dl = DataLoader(ds, batch_size=32, shuffle=True)\n",
    "\n",
    "# Show a batch\n",
    "x,y = next(iter(dl))\n",
    "show_timgs(x)\n",
    "print(y)\n",
    "print(\"===\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pretty neat!:)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Multisource MonoMNIST DataModule\n",
    "Next, we work on creating a pytorch-lightning's DataModule class that encompasses this multi-source dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data.datamodules import MultiMonoMNISTDataModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection = {\"red\": RedMNIST,\n",
    "              \"green\": GreenMNIST,\n",
    "              \"blue\": BlueMNIST,\n",
    "              \"gray\": GrayMNIST}\n",
    "\n",
    "def get_mono_dsets(colors: List[str], collection:Dict[str, MonoMNIST]):\n",
    "    dsets = []\n",
    "    for color in colors:\n",
    "        dsets.append(collection[color])\n",
    "    return dsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = ['red', 'green']\n",
    "dsets = get_mono_dsets(colors,collection)\n",
    "seed = collection['red'].seed\n",
    "in_shape = (3, 32,32)\n",
    "batch_size=32\n",
    "print(\"===Num. of observations===\")\n",
    "print([len(ds) for ds in dsets])\n",
    "\n",
    "# Create a multi-source dataset\n",
    "ds = ConcatDataset(dsets)\n",
    "dm = MultiMonoMNISTDataModule(\n",
    "    full_ds=ds,\n",
    "    colors=colors,\n",
    "    seed=seed,\n",
    "    in_shape=in_shape,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    ")\n",
    "dm.setup('fit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dl = dm.train_dataloader()\n",
    "# Show a batch\n",
    "x,y = next(iter(dl))\n",
    "show_timgs(x)\n",
    "print(y)\n",
    "print(\"===\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ta-Da!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Improvement 1: Multisource Mono-MNIST Dataset\n",
    "Create a new dataset class that holes multiple MonoMNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data.datasets import MultiMonoMNIST\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = MultiMonoMNIST(\n",
    "    data_root=mono_dir,\n",
    "    colors=colors,\n",
    "    seed=seed\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.get_mono_dsets(ds.colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds0, ds1 = ds.dsets\n",
    "x,y = ds0[1]\n",
    "info(x)\n",
    "print(y)\n",
    "show_timg(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    idx = np.random.randint(len(ds))\n",
    "    x,y = ds[idx]\n",
    "    info(x)\n",
    "    show_timg(x)\n",
    "    plt.title(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improvement 2: Use the multisource MonoMNIST dataset as input to the datamodule\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm = MultiMonoMNISTDataModule(\n",
    "    full_ds=ds,\n",
    "    colors=ds.colors,\n",
    "    seed=ds.seed,\n",
    "    in_shape=in_shape,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    ")\n",
    "dm.setup('fit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = dm.train_dataloader()\n",
    "# Show a batch\n",
    "x,y = next(iter(dl))\n",
    "show_timgs(x)\n",
    "print(y)\n",
    "print(\"===\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Workflow\n",
    "- Specify dataset settings \n",
    "  - colors, batch_size, shape of each datapoint (`in_shape`)\n",
    "- Initialize a multisource MonoMNIST dataset\n",
    "- Initialize a multisource MonoMNIST datamodule using the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data.datasets import MultiMonoMNIST\n",
    "from src.data.datamodules import MultiMonoMNISTDataModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset settings\n",
    "data_dir = Path(\"/data/hayley-old/Tenanbaum2000/data/Mono-MNIST/\")\n",
    "colors = ['red', 'green']\n",
    "seed = 123\n",
    "in_shape = (3, 32,32)\n",
    "batch_size = 32\n",
    "\n",
    "\n",
    "# # Create a concat dataset from multiple mono-mnist datasets\n",
    "# ds = MultiMonoMNIST(\n",
    "#     data_root=data_dir,\n",
    "#     colors=colors,\n",
    "#     seed=seed\n",
    "# )\n",
    "# print(\"===Num. of observations===\")\n",
    "# print([len(d) for d in ds.dsets])\n",
    "\n",
    "# Create a multisource mono-mnist datamodule\n",
    "dm = MultiMonoMNISTDataModule(\n",
    "    data_root=data_dir,\n",
    "    colors=colors,\n",
    "    seed=seed,\n",
    "    in_shape=in_shape,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    ")\n",
    "dm.setup('fit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = dm.full_ds.dsets[0][10]\n",
    "info(x)\n",
    "y\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dm.name)\n",
    "dl = dm.train_dataloader()\n",
    "# Show a batch\n",
    "x,y = next(iter(dl))\n",
    "show_timgs(x)\n",
    "print(y)\n",
    "print(\"===\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "conda-env-test-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
