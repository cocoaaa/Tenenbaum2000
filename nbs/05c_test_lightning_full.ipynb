{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,sys\n",
    "import re\n",
    "import math\n",
    "from datetime import datetime\n",
    "import time\n",
    "sys.dont_write_bytecode = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.color import rgb2gray\n",
    "from skimage.transform import resize\n",
    "\n",
    "from pathlib import Path\n",
    "from typing import List, Set, Dict, Tuple, Optional, Iterable, Mapping, Union, Callable\n",
    "\n",
    "from pprint import pprint\n",
    "from ipdb import set_trace as brpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from  torch.linalg import norm as tnorm\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.core.lightning import LightningModule\n",
    "from pytorch_lightning import loggers as pl_loggers\n",
    "# Select Visible GPU\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[print(x) for x in [\n",
    "    torch.cuda.is_available(),\n",
    "    torch.cuda.is_initialized(),\n",
    "    torch.backends.cuda.is_built(),\n",
    "    torch.backends.cudnn.version(),\n",
    "    torch.backends.cudnn.is_available(),\n",
    "    torch.backends.cudnn.enabled,\n",
    "    torch.backends.cudnn.benchmark\n",
    "]];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Path \n",
    "1. Add project root and src folders to `sys.path`\n",
    "2. Set DATA_ROOT to `maptile_v2` folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "this_nb_path = Path(os.getcwd())\n",
    "ROOT = this_nb_path.parent\n",
    "SRC = ROOT/'src'\n",
    "DATA_ROOT = Path(\"/data/hayley-old/maptiles_v2/\")\n",
    "paths2add = [this_nb_path, ROOT]\n",
    "\n",
    "print(\"Project root: \", str(ROOT))\n",
    "print('Src folder: ', str(SRC))\n",
    "print(\"This nb path: \", str(this_nb_path))\n",
    "\n",
    "\n",
    "for p in paths2add:\n",
    "    if str(p) not in sys.path:\n",
    "        sys.path.insert(0, str(p))\n",
    "        print(f\"\\n{str(p)} added to the path.\")\n",
    "        \n",
    "# print(sys.path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from src.data.datasets.maptiles import Maptiles, MapStyles\n",
    "from src.data.datamodules.maptiles_datamodule import MaptilesDataModule\n",
    "\n",
    "from src.data.transforms.transforms import Identity\n",
    "from src.models.plmodules.three_fcs import ThreeFCs\n",
    "\n",
    "from src.visualize.utils import show_timgs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start experiment \n",
    "Given a maptile, predict its style as one of OSM, CartoVoyager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in [1,2,3]:\n",
    "#     for j in [1,2,3]:\n",
    "#         # Instantiate data module\n",
    "#         cities = ['paris']\n",
    "#         styles = ['OSMDefault', 'CartoVoyagerNoLabels']\n",
    "#         zooms = ['14']\n",
    "#         dm = MaptilesDataModule(data_root=DATA_ROOT,\n",
    "#                                 cities=cities,\n",
    "#                                 styles=styles,\n",
    "#                                 zooms=zooms)\n",
    "\n",
    "#         # Instantiate the pl Module\n",
    "#         nh1, nh2 = 100*i,100*j\n",
    "#         dim_in = dm.in_size**2*dm.n_channels\n",
    "#         n_classes = len(dm.styles)\n",
    "#         model = ThreeFCs( dim_in=dim_in, nh1=nh1, nh2=nh2, n_classes=n_classes)\n",
    "#         print(model.hparams)\n",
    "#         # Instantiate a PL `Trainer` object\n",
    "#         # -- most basic trainer: uses good defaults, eg: auto-tensorboard logging, checkpoints, logs, etc.\n",
    "#         # -- Pass the data module along with a pl module\n",
    "#         # ref: https://www.learnopencv.com/tensorboard-with-pytorch-lightning/\n",
    "#         tb_logger = pl_loggers.TensorBoardLogger(save_dir='lightning_logs', name='three_fcs')\n",
    "#         trainer_config = {\n",
    "#             'gpus':1,\n",
    "#             'max_epochs': 20,\n",
    "#             'progress_bar_refresh_rate':10,\n",
    "#             'auto_lr_find': True,\n",
    "#             'terminate_on_nan':True,\n",
    "#             'val_check_interval': 0.25, #iterations\n",
    "#             'logger':tb_logger\n",
    "#         }\n",
    "#         trainer = pl.Trainer(**trainer_config)\n",
    "#         # trainer = pl.Trainer(fast_dev_run=True)\n",
    "\n",
    "#         trainer.fit(model, dm)\n",
    "\n",
    "#         # Finally,\n",
    "#         # Log this model's hyperparmeters to tensorboard\n",
    "#         hparams = dict(model.hparams)\n",
    "#         metrics = {'hparam/acc': model.acc.compute().item()}\n",
    "#         model.logger.experiment.add_hparams(hparam_dict=hparams,\n",
    "#                                             metric_dict=metrics) #how to store the 'best' value of the metric?\n",
    "#         # Alternatively, use pl.Logger's method \"log_hyperparameters\"\n",
    "# #         logger.log_hyperparams(hparams, metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Log this model's hyperparmeters to tensorboard\n",
    "# model.logger.experiment.add_hparams(hparam_dict=dict(model.hparams), \n",
    "#                                     metric_dict={'hparam/acc': model.acc.compute().item()}) #how to store the 'best' value of the metric?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models.plmodules.vanilla_vae import VanillaVAE\n",
    "from pl_bolts.callbacks import LatentDimInterpolator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate data module\n",
    "cities = ['paris']\n",
    "styles = ['OSMDefault', 'CartoVoyagerNoLabels']\n",
    "zooms = ['14']\n",
    "dm = MaptilesDataModule(data_root=DATA_ROOT,\n",
    "                        cities=cities,\n",
    "                        styles=styles,\n",
    "                        zooms=zooms,\n",
    "                       bs=1)\n",
    "\n",
    "# Instantiate the pl Module\n",
    "in_shape = (3,64,64)\n",
    "latent_dim = 10\n",
    "hidden_dims = [32,64,128,256,512]\n",
    "act_fn = nn.LeakyReLU()\n",
    "model = VanillaVAE(in_shape, \n",
    "                     latent_dim,\n",
    "                     hidden_dims,\n",
    "                     act_fn)\n",
    "print(model.hparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate a PL `Trainer` object\n",
    "# -- most basic trainer: uses good defaults, eg: auto-tensorboard logging, checkpoints, logs, etc.\n",
    "# -- Pass the data module along with a pl module\n",
    "# ref: https://www.learnopencv.com/tensorboard-with-pytorch-lightning/\n",
    "tb_logger = pl_loggers.TensorBoardLogger(save_dir='lightning_logs', name='vanilla_vae')\n",
    "trainer_config = {\n",
    "    'gpus':1,\n",
    "    'max_epochs': 200,\n",
    "    'progress_bar_refresh_rate':20,\n",
    "    'auto_lr_find': True,\n",
    "    'terminate_on_nan':True,\n",
    "    'val_check_interval': 0.25, #iterations\n",
    "    'logger':tb_logger,\n",
    "    'callbacks':[LatentDimInterpolator()]\n",
    "}\n",
    "trainer = pl.Trainer(**trainer_config)\n",
    "# trainer = pl.Trainer(fast_dev_run=True)\n",
    "\n",
    "trainer.fit(model, dm)\n",
    "\n",
    "# Finally,\n",
    "# Log this model's hyperparmeters to tensorboard\n",
    "# hparams = dict(model.hparams)\n",
    "# metrics = {'hparam/acc': model.hparams[\"loss\"]}\n",
    "# model.logger.experiment.add_hparams(hparam_dict=hparams,\n",
    "#                                     metric_dict=metrics) #how to store the 'best' value of the metric?\n",
    "# Alternatively, use pl.Logger's method \"log_hyperparameters\"\n",
    "#         logger.log_hyperparams(hparams, metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2\n",
    "# Instantiate data module\n",
    "cities = ['paris']\n",
    "styles = ['OSMDefault', 'CartoVoyagerNoLabels']\n",
    "zooms = ['14']\n",
    "dm = MaptilesDataModule(data_root=DATA_ROOT,\n",
    "                        cities=cities,\n",
    "                        styles=styles,\n",
    "                        zooms=zooms,\n",
    "                       bs=1)\n",
    "\n",
    "# Instantiate the pl Module\n",
    "in_shape = (3,64,64)\n",
    "latent_dim = 10\n",
    "hidden_dims = [32,64,128,256,512]\n",
    "act_fn = nn.LeakyReLU()\n",
    "model = VanillaVAE64(in_shape, \n",
    "                     latent_dim,\n",
    "                     hidden_dims,\n",
    "                     act_fn)\n",
    "print(model.hparams)\n",
    "# Instantiate a PL `Trainer` object\n",
    "# -- most basic trainer: uses good defaults, eg: auto-tensorboard logging, checkpoints, logs, etc.\n",
    "# -- Pass the data module along with a pl module\n",
    "# ref: https://www.learnopencv.com/tensorboard-with-pytorch-lightning/\n",
    "tb_logger = pl_loggers.TensorBoardLogger(save_dir='lightning_logs', name='vanilla_vae')\n",
    "trainer_config = {\n",
    "#     'gpus':1,\n",
    "    'max_epochs': 200,\n",
    "    'progress_bar_refresh_rate':20,\n",
    "    'auto_lr_find': True,\n",
    "    'terminate_on_nan':True,\n",
    "    'val_check_interval': 0.25, #iterations\n",
    "    'logger':tb_logger\n",
    "}\n",
    "trainer = pl.Trainer(**trainer_config)\n",
    "# trainer = pl.Trainer(fast_dev_run=True)\n",
    "\n",
    "trainer.fit(model, dm)\n",
    "\n",
    "# Finally,\n",
    "# Log this model's hyperparmeters to tensorboard\n",
    "# hparams = dict(model.hparams)\n",
    "# metrics = {'hparam/acc': model.hparams[\"loss\"]}\n",
    "# model.logger.experiment.add_hparams(hparam_dict=hparams,\n",
    "#                                     metric_dict=metrics) #how to store the 'best' value of the metric?\n",
    "# Alternatively, use pl.Logger's method \"log_hyperparameters\"\n",
    "#         logger.log_hyperparams(hparams, metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3\n",
    "# Instantiate data module\n",
    "cities = ['paris']\n",
    "styles = ['OSMDefault', 'CartoVoyagerNoLabels']\n",
    "zooms = ['14']\n",
    "dm = MaptilesDataModule(data_root=DATA_ROOT,\n",
    "                        cities=cities,\n",
    "                        styles=styles,\n",
    "                        zooms=zooms,\n",
    "                       bs=1)\n",
    "\n",
    "# Instantiate the pl Module\n",
    "in_shape = (3,64,64)\n",
    "latent_dim = 20\n",
    "hidden_dims = [32,64,128,256,512]\n",
    "act_fn = nn.LeakyReLU()\n",
    "model = VanillaVAE64(in_shape, \n",
    "                     latent_dim,\n",
    "                     hidden_dims,\n",
    "                     act_fn)\n",
    "print(model.hparams)\n",
    "# Instantiate a PL `Trainer` object\n",
    "# -- most basic trainer: uses good defaults, eg: auto-tensorboard logging, checkpoints, logs, etc.\n",
    "# -- Pass the data module along with a pl module\n",
    "# ref: https://www.learnopencv.com/tensorboard-with-pytorch-lightning/\n",
    "tb_logger = pl_loggers.TensorBoardLogger(save_dir='lightning_logs', name='vanilla_vae')\n",
    "trainer_config = {\n",
    "#     'gpus':1,\n",
    "    'max_epochs': 200,\n",
    "    'progress_bar_refresh_rate':20,\n",
    "    'auto_lr_find': True,\n",
    "    'terminate_on_nan':True,\n",
    "    'val_check_interval': 0.25, #iterations\n",
    "    'logger':tb_logger\n",
    "}\n",
    "trainer = pl.Trainer(**trainer_config)\n",
    "# trainer = pl.Trainer(fast_dev_run=True)\n",
    "\n",
    "trainer.fit(model, dm)\n",
    "\n",
    "# Finally,\n",
    "# Log this model's hyperparmeters to tensorboard\n",
    "# hparams = dict(model.hparams)\n",
    "# metrics = {'hparam/acc': model.hparams[\"loss\"]}\n",
    "# model.logger.experiment.add_hparams(hparam_dict=hparams,\n",
    "#                                     metric_dict=metrics) #how to store the 'best' value of the metric?\n",
    "# Alternatively, use pl.Logger's method \"log_hyperparameters\"\n",
    "#         logger.log_hyperparams(hparams, metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4\n",
    "# Instantiate data module\n",
    "cities = ['paris']\n",
    "styles = ['OSMDefault', 'CartoVoyagerNoLabels']\n",
    "zooms = ['14']\n",
    "dm = MaptilesDataModule(data_root=DATA_ROOT,\n",
    "                        cities=cities,\n",
    "                        styles=styles,\n",
    "                        zooms=zooms,\n",
    "                       bs=1)\n",
    "\n",
    "# Instantiate the pl Module\n",
    "in_shape = (3,64,64)\n",
    "latent_dim = 30\n",
    "hidden_dims = [32,64,128,256,512]\n",
    "act_fn = nn.LeakyReLU()\n",
    "model = VanillaVAE64(in_shape, \n",
    "                     latent_dim,\n",
    "                     hidden_dims,\n",
    "                     act_fn)\n",
    "print(model.hparams)\n",
    "# Instantiate a PL `Trainer` object\n",
    "# -- most basic trainer: uses good defaults, eg: auto-tensorboard logging, checkpoints, logs, etc.\n",
    "# -- Pass the data module along with a pl module\n",
    "# ref: https://www.learnopencv.com/tensorboard-with-pytorch-lightning/\n",
    "tb_logger = pl_loggers.TensorBoardLogger(save_dir='lightning_logs', name='vanilla_vae')\n",
    "trainer_config = {\n",
    "#     'gpus':1,\n",
    "    'max_epochs': 200,\n",
    "    'progress_bar_refresh_rate':20,\n",
    "    'auto_lr_find': True,\n",
    "    'terminate_on_nan':True,\n",
    "    'val_check_interval': 0.25, #iterations\n",
    "    'logger':tb_logger\n",
    "}\n",
    "trainer = pl.Trainer(**trainer_config)\n",
    "# trainer = pl.Trainer(fast_dev_run=True)\n",
    "\n",
    "trainer.fit(model, dm)\n",
    "\n",
    "# Finally,\n",
    "# Log this model's hyperparmeters to tensorboard\n",
    "# hparams = dict(model.hparams)\n",
    "# metrics = {'hparam/acc': model.hparams[\"loss\"]}\n",
    "# model.logger.experiment.add_hparams(hparam_dict=hparams,\n",
    "#                                     metric_dict=metrics) #how to store the 'best' value of the metric?\n",
    "# Alternatively, use pl.Logger's method \"log_hyperparameters\"\n",
    "#         logger.log_hyperparams(hparams, metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pl.Metrics Module\n",
    "python-lightning provides a class of metrics that inherits from `nn.Module`\n",
    "`Metrics` base class's `forward(x)` method does the 2 following actions:\n",
    "- Calls `update()` on its input `x`\n",
    "- Simultaneously, returns the value of the metric over the input\n",
    "\n",
    "Other key methods:\n",
    "- `Metric.update()`\n",
    "- `Metric.compute()`\n",
    "- `Metric.reset()`\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.visualize.utils import show_timgs, show_timg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 36\n",
    "with torch.no_grad():\n",
    "    sampled_recons = model.samaple(n_samples, model.device)\n",
    "    show_timgs(sampled_recons.detach())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recons\n",
    "with torch.no_grad():\n",
    "    for n in range(n_samples):\n",
    "        x,y = next(iter(dm.train_dataloader()))\n",
    "        mu, log_var,recon = model(x)[\"mu\"], model(x)[\"log_var\"], model(x)[\"recon\"]\n",
    "        show_timg(recon.detach().squeeze())\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:torch2]",
   "language": "python",
   "name": "conda-env-torch2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
