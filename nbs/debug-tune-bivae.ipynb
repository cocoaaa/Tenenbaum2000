{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "painful-provider",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "proud-lightweight",
   "metadata": {},
   "source": [
    "## Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "excessive-fairy",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "binding-columbus",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,sys\n",
    "import re\n",
    "import math\n",
    "from datetime import datetime\n",
    "import time\n",
    "sys.dont_write_bytecode = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dress-detector",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import joblib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pathlib import Path\n",
    "from typing import List, Set, Dict, Tuple, Optional, Iterable, Mapping, Union, Callable, TypeVar\n",
    "\n",
    "from pprint import pprint\n",
    "from ipdb import set_trace as brpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "southeast-petersburg",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from  torch.linalg import norm as tnorm\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.core.lightning import LightningModule\n",
    "from pytorch_lightning import loggers as pl_loggers\n",
    "from pytorch_lightning.tuner.tuning import Tuner\n",
    "\n",
    "\n",
    "# Select Visible GPU\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\" \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "placed-filter",
   "metadata": {},
   "source": [
    "## Set Path \n",
    "1. Add project root and src folders to `sys.path`\n",
    "2. Set DATA_ROOT to `maptile_v2` folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proof-summit",
   "metadata": {},
   "outputs": [],
   "source": [
    "this_nb_path = Path(os.getcwd())\n",
    "ROOT = this_nb_path.parent\n",
    "SRC = ROOT/'src'\n",
    "DATA_ROOT = Path(\"/data/hayley-old/maptiles_v2/\")\n",
    "paths2add = [this_nb_path, ROOT]\n",
    "\n",
    "print(\"Project root: \", str(ROOT))\n",
    "print('Src folder: ', str(SRC))\n",
    "print(\"This nb path: \", str(this_nb_path))\n",
    "\n",
    "\n",
    "for p in paths2add:\n",
    "    if str(p) not in sys.path:\n",
    "        sys.path.insert(0, str(p))\n",
    "        print(f\"\\n{str(p)} added to the path.\")\n",
    "        \n",
    "# print(sys.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "illegal-maintenance",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data transforms\n",
    "from src.data.transforms.transforms import Identity, Unnormalizer, LinearRescaler\n",
    "from src.data.transforms.functional import unnormalize\n",
    "\n",
    "# Utils\n",
    "from src.visualize.utils import show_timg, show_timgs, show_batch, make_grid_from_tensors\n",
    "from src.utils.misc import info, get_next_version_path\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "friendly-christopher",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataModules\n",
    "from src.data.datamodules import MNISTDataModule, MNISTMDataModule, MonoMNISTDataModule\n",
    "from src.data.datamodules import MultiMonoMNISTDataModule\n",
    "from src.data.datamodules.multisource_rotated_mnist_datamodule import MultiRotatedMNISTDataModule\n",
    "from src.data.datamodules.multisource_maptiles_datamodule import MultiMaptilesDataModule\n",
    "\n",
    "\n",
    "# plModules\n",
    "from src.models.plmodules.vanilla_vae import VanillaVAE\n",
    "from src.models.plmodules.iwae import IWAE\n",
    "from src.models.plmodules.bilatent_vae import BiVAE\n",
    "\n",
    "# Evaluations\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from pytorch_lightning.utilities.cloud_io import load as pl_load\n",
    "from src.evaluator.qualitative import save_content_transfers, save_style_transfers, run_both_transfers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "handmade-legend",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Find the best hparam setting for a specific BiVAE model trained on a specific datamodule.\n",
    "\n",
    "Required args:\n",
    "    --model_name: eg. \"vae\", \"iwae\", \"bivae\"\n",
    "    --data_name: eg. \"maptiles\", \"mnist\", \"multi_mono_mnist\"\n",
    "    --latent_dim: int, eg. 10\n",
    "\n",
    "Optional args: (partial)\n",
    "    --hidden_dims: eg. --hidden_dims 32 64 128 256 (which is default)\n",
    "\n",
    "Hyperparameter space:\n",
    "- latent_dim = [16, 32, 63, 128]\n",
    "- is_contrasive =  [False, True]\n",
    "- kld_weight = [\n",
    "- adv_loss_weight = [5, 15, 45, 135, 405, 1215]\n",
    "- batch_size = [32, 64, 128, 256, 514, 1028]\n",
    "- learning_rate =\n",
    "\n",
    "To run: (at the root of the project, ie. /data/hayley-old/Tenanbaum2000\n",
    "# Values for adv_weight, latent_dim, batch_size, lr, is_contrasive will be overwritten\n",
    "# as the searched hyperparmeter values\n",
    "\n",
    " nohup python tune_hparams_bivae.py --model_name=\"bivae\" \\\n",
    "--latent_dim=10 --hidden_dims 32 64 128 256 --adv_dim 32 32 32 --adv_weight 15.0 \\\n",
    "--data_name=\"multi_mono_mnist\" --colors red green blue --n_styles=3 \\\n",
    "--gpu_id=2 --max_epochs=300 --batch_size=128 -lr 1e-3  --terminate_on_nan=True  \\\n",
    "--log_root=\"/data/hayley-old/Tenanbaum2000/lightning_logs/2021-01-13-ray/\" &\n",
    "\n",
    " nohup python tune_hparams_bivae.py --model_name=\"bivae\" \\\n",
    "--latent_dim=10 --hidden_dims 32 64 128 256 --adv_dim 32 32 32 --adv_weight 15.0 \\\n",
    "--use_beta_scheduler \\\n",
    "--data_name=\"multi_mono_mnist\" --colors red green blue --n_styles=3 \\\n",
    "--gpu_id=2 --max_epochs=300 --batch_size=128 -lr 1e-3  --terminate_on_nan=True  \\\n",
    "--log_root=\"/data/hayley-old/Tenanbaum2000/lightning_logs/2021-01-14-ray/\" &\n",
    "\n",
    "# View the Ray dashboard at http://127.0.0.1:8265\n",
    "# Run this at  local terminal:\n",
    "# ssh -NfL 8265:localhost:8265 arya\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import time\n",
    "from argparse import ArgumentParser, Namespace\n",
    "from collections import OrderedDict\n",
    "from pathlib import Path\n",
    "from typing import List, Set,Any, Dict, Tuple, Optional, Iterable, Mapping, Union, Callable, TypeVar\n",
    "import warnings\n",
    "from pprint import pprint\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import torchvision\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import loggers as pl_loggers\n",
    "from pytorch_lightning.callbacks import LearningRateMonitor\n",
    "\n",
    "# Ray\n",
    "import ray\n",
    "from ray import tune\n",
    "from ray.tune import CLIReporter\n",
    "from ray.tune.integration.pytorch_lightning import TuneReportCallback\n",
    "\n",
    "from src.callbacks.recon_logger import ReconLogger\n",
    "from src.callbacks.hist_logger import  HistogramLogger\n",
    "from src.callbacks.beta_scheduler import BetaScheduler\n",
    "\n",
    "# src helpers\n",
    "from src.utils.misc import info, n_iter_per_epoch\n",
    "from src.models.model_wrapper import ModelWrapper\n",
    "\n",
    "# utils for instatiating a selected datamodule and a selected model\n",
    "from utils import get_model_class, get_dm_class\n",
    "from utils import instantiate_model, instantiate_dm\n",
    "from utils import add_base_arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gentle-encounter",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_tune(args: Union[Dict, Namespace]):\n",
    "    # Init. datamodule and model\n",
    "    dm = instantiate_dm(args)\n",
    "    dm.setup('fit')\n",
    "    model = instantiate_model(args)\n",
    "\n",
    "    # Specify logger\n",
    "    exp_name = f'{model.name}_{dm.name}'\n",
    "    print('Exp name: ', exp_name)\n",
    "    tb_logger = pl_loggers.TensorBoardLogger(save_dir=args.log_root,\n",
    "                                             name=exp_name,\n",
    "                                             default_hp_metric=False,\n",
    "                                             )\n",
    "    log_dir = Path(tb_logger.log_dir)\n",
    "    print(\"Log Dir: \", log_dir)\n",
    "    # breakpoint()\n",
    "    if not log_dir.exists():\n",
    "        log_dir.mkdir(parents=True)\n",
    "        print(\"Created: \", log_dir)\n",
    "\n",
    "    # Specify callbacks\n",
    "    callbacks = [\n",
    "        LearningRateMonitor(logging_interval='epoch'),\n",
    "        TuneReportCallback(\n",
    "            {\n",
    "            'loss': 'val_loss',\n",
    "            'mean_accuracy': 'val/style_acc', # use the string after pl.Module's \"self.log(\"\n",
    "            },\n",
    "            on=\"validation_end\"\n",
    "        ),\n",
    "        # HistogramLogger(hist_epoch_interval=args.hist_epoch_interval),\n",
    "        # ReconLogger(recon_epoch_interval=args.recon_epoch_interval),\n",
    "        #         EarlyStopping('val_loss', patience=10),\n",
    "    ]\n",
    "    if args.use_beta_scheduler:\n",
    "        max_iters = n_iter_per_epoch(dm.train_dataloader()) * args.max_epochs\n",
    "        callbacks.append(BetaScheduler(max_iters,\n",
    "                                       start=args.beta_start,\n",
    "                                       stop=args.beta_stop,\n",
    "                                       n_cycle=args.beta_n_cycle,\n",
    "                                       ratio=args.beta_ratio,\n",
    "                                       log_tag=args.beta_log_tag))\n",
    "\n",
    "    trainer_overwrites = {\n",
    "        'gpus':1, #use a single gpu\n",
    "        'progress_bar_refresh_rate':0, # don't print out progress bar\n",
    "        'terminate_on_nan':True,\n",
    "        'check_val_every_n_epoch':10,\n",
    "        'logger': tb_logger,\n",
    "        'callbacks': callbacks\n",
    "    }\n",
    "\n",
    "    # Init. trainer\n",
    "    trainer = pl.Trainer.from_argparse_args(args, **trainer_overwrites)\n",
    "\n",
    "    # Log model's computational graph\n",
    "    model_wrapper = ModelWrapper(model)\n",
    "    # tb_logger.experiment.add_graph(model_wrapper, model.)\n",
    "    tb_logger.log_graph(model_wrapper)\n",
    "\n",
    "\n",
    "    # ------------------------------------------------------------------------\n",
    "    # Run the experiment\n",
    "    # ------------------------------------------------------------------------\n",
    "    start_time = time.time()\n",
    "    print(f\"{exp_name} started...\")\n",
    "    print(f\"Logging to {Path(tb_logger.log_dir).absolute()}\")\n",
    "    trainer.fit(model, dm)\n",
    "    print(f\"Finished at ep {trainer.current_epoch, trainer.batch_idx}\")\n",
    "\n",
    "\n",
    "    # ------------------------------------------------------------------------\n",
    "    # Log the best score and current experiment's hyperparameters\n",
    "    # ------------------------------------------------------------------------\n",
    "    hparams = model.hparams.copy()\n",
    "    hparams.update(dm.hparams)\n",
    "    best_score = trainer.checkpoint_callback.best_model_score.item()\n",
    "    metrics = {'hparam/best_score': best_score}  # todo: define a metric and use it here\n",
    "    trainer.logger.log_hyperparams(hparams, metrics)\n",
    "\n",
    "    print(\"Logged hparams and metrics...\")\n",
    "    print(\"\\t hparams: \")\n",
    "    pprint(hparams)\n",
    "    print(\"=====\")\n",
    "    print(\"\\t metrics: \", metrics)\n",
    "    print(f\"Training Done: took {time.time() - start_time}\")\n",
    "\n",
    "    # ------------------------------------------------------------------------\n",
    "    # Evaluation\n",
    "    #   1. Reconstructions:\n",
    "    #     x --> model.encoder(x) --> theta_z\n",
    "    #     --> sample N latent codes from the Pr(z; theta_z)\n",
    "    #     --> model.decoder(z) for each sampled z's\n",
    "    #   2. Embedding:\n",
    "    #       a mini-batch input -> mu_z, logvar_z\n",
    "    #       -> rsample\n",
    "    #       -> project to 2D -> visualize\n",
    "    #   3. Inspect the topology/landscape of the learned latent space\n",
    "    #     Latent traversal: Pick a dimension of the latent space.\n",
    "    #     - Keep all other dimensions' values constant.\n",
    "    #     - Vary the chosen dimenion's values (eg. linearly, spherically)\n",
    "    #     - and decode the latent codes. Show the outputs of the decoder.\n",
    "    #   4. Marginal Loglikelihood of train/val/test dataset\n",
    "    # ------------------------------------------------------------------------\n",
    "    # print(\"Evaluations...\")\n",
    "    # model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "polished-medicine",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(user_args: List[str]):\n",
    "    parser = ArgumentParser()\n",
    "\n",
    "    # ------------------------------------------------------------------------\n",
    "    # Add general arguments for this CLI script for training/testing\n",
    "    # ------------------------------------------------------------------------\n",
    "    parser = add_base_arguments(parser)\n",
    "    args, unknown = parser.parse_known_args(user_args)\n",
    "    print(\"Base CLI args: \")\n",
    "    pprint(args)\n",
    "\n",
    "    # ------------------------------------------------------------------------\n",
    "    # Add model/datamodule/trainer specific args\n",
    "    # ------------------------------------------------------------------------\n",
    "    model_class = get_model_class(args.model_name)\n",
    "    dm_class = get_dm_class(args.data_name)\n",
    "    parser = model_class.add_model_specific_args(parser)\n",
    "    parser = dm_class.add_model_specific_args(parser)\n",
    "    parser = pl.Trainer.add_argparse_args(parser)\n",
    "\n",
    "    # RayTune args\n",
    "    parser.add_argument('--n_cpus',  type=int, default=8, help='Num of CPUs per trial')\n",
    "    parser.add_argument(\"--gpu_ids\", type=str, required=True, nargs='*',\n",
    "                        help=\"GPU ID(s) to use\") #Returns an empty list if not specified\n",
    "    parser.add_argument(\"--n_ray_samples\", type=int, default=1,\n",
    "                         help=\"Num of Ray Tune's run argument, num_samples\")\n",
    "    parser.add_argument(\"--ray_log_dir\", type=str, default=\"/data/log/ray\",\n",
    "                        help=\"dir to save training results from Ray\")\n",
    "    # Callback switch args\n",
    "    parser = BetaScheduler.add_argparse_args(parser)\n",
    "    # parser.add_argument(\"--hist_epoch_interval\", type=int, default=10, help=\"Epoch interval to plot histogram of q's parameter\")\n",
    "    # parser.add_argument(\"--recon_epoch_interval\", type=int, default=10, help=\"Epoch interval to plot reconstructions of train and val samples\")\n",
    "    args = parser.parse_args(user_args)\n",
    "    print(\"Final args: \")\n",
    "    pprint(args)\n",
    "\n",
    "    # Select Visible GPU\n",
    "    os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = ','.join(args.gpu_ids)\n",
    "    print(\"===GPUs===\")\n",
    "    print(os.environ[\"CUDA_VISIBLE_DEVICES\"])\n",
    "\n",
    "    def set_hparam_and_train_closure(config: Dict[str, Any]):\n",
    "        \"\"\"Use the (k,v) in `overwrite` to update the args\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        config: Hyperparam search space as a Dict[hparam-name, value of the hpamram]\n",
    "            This dict object is a sample point from the Ray's Hyperparameter space,\n",
    "            and will be used to overwrite the `args`'s key-value with its key-value.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        None. Train the model in the specified hyperparmeter space\n",
    "        \"\"\"\n",
    "        print(\"Inside the clousure===\")\n",
    "        pprint(args)\n",
    "        print(\"===\")\n",
    "        pprint(config)\n",
    "\n",
    "        d_args =  vars(args)\n",
    "        for k, v in config.items():\n",
    "            d_args[k] = v\n",
    "            print(\"Overwrote args: \", k)\n",
    "\n",
    "        # Start experiment with this overwritten hyperparams\n",
    "        train_tune(args)\n",
    "\n",
    "    # ------------------------------------------------------------------------\n",
    "    # Specify hyperparameter search space\n",
    "    # ------------------------------------------------------------------------\n",
    "    search_space = {\n",
    "        # \"latent_dim\": tune.grid_search([10, 20, 60, 100]),\n",
    "        'enc_type': tune.choice(['conv', 'resnet']),\n",
    "        'dec_type': tune.choice(['conv', 'resnet']),\n",
    "        'is_contrasive': tune.choice([False, True]),\n",
    "        'kld_weight': tune.choice(np.array([0.5*(2**i) for i in range(12)])), #[0.5, 1.0, 2.0, 4.0, 8.0, 16.0, 32., 64, 128., 256, 512, 1024]), #np.array([0.5*(2**i) for i in range(12)])\n",
    "        'use_beta_scheduler': False, #tune.grid_search([False,True]),\n",
    "        'adv_loss_weight': tune.choice(np.logspace(0.0, 7.0, num=8, base=3.0)),\n",
    "        'learning_rate': tune.loguniform(1e-4, 1e-1), #tune.grid_search(list(np.logspace(-4., -1, num=10))),\n",
    "        'batch_size': tune.choice([32, 64, 128,]),\n",
    "    }\n",
    "    \n",
    "\n",
    "    # ------------------------------------------------------------------------\n",
    "    # Start hyperparameter search using Ray\n",
    "    # ------------------------------------------------------------------------\n",
    "#     ray.shutdown()\n",
    "#     ray.init(log_to_driver=False)\n",
    "    # search_alg =\n",
    "\n",
    "    reporter = CLIReporter(\n",
    "        parameter_columns=list(search_space.keys()),\n",
    "        metric_columns=[\"loss\", \"mean_accuracy\", \"training_iteration\"])\n",
    "    \n",
    "#     breakpoint()\n",
    "    \n",
    "    analysis = tune.run(\n",
    "        set_hparam_and_train_closure,\n",
    "        config=search_space,\n",
    "        metric='loss', #set to val_loss\n",
    "        mode='min',\n",
    "        # search_alg=search_alg,\n",
    "        num_samples=args.n_ray_samples,\n",
    "        verbose=1,\n",
    "        progress_reporter=reporter,\n",
    "        name=\"Tune-BiVAE\", # name of experiment\n",
    "        local_dir= args.ray_log_dir,\n",
    "        resources_per_trial={\"cpu\":args.n_cpus, \"gpu\": len(args.gpu_ids)}, # there are 16cpus in arya machine; so at a time 16/2=8 trials will be run concurrently\n",
    "    )\n",
    "    print(\"Best hyperparameters found were: \", analysis.best_config)\n",
    "\n",
    "    dfs = analysis.fetch_trial_dataframes()\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "#         # Debug\n",
    "#     config = {\n",
    "#         # \"latent_dim\": tune.grid_search([10, 20, 60, 100]),\n",
    "#         'enc_type': 'conv',\n",
    "#         'dec_type': 'resnet',\n",
    "#         'is_contrasive': False,\n",
    "#         'kld_weight': 1.0, \n",
    "#         'use_beta_scheduler': False, #tune.grid_search([False,True]),\n",
    "#         'adv_loss_weight': 1.0, \n",
    "#         'learning_rate': 1e-4, \n",
    "#         'batch_size': 32,\n",
    "#     }\n",
    "#     set_hparam_and_train_closure(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "religious-spouse",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(user_args: List[str]):\n",
    "    parser = ArgumentParser()\n",
    "\n",
    "    # ------------------------------------------------------------------------\n",
    "    # Add general arguments for this CLI script for training/testing\n",
    "    # ------------------------------------------------------------------------\n",
    "    parser = add_base_arguments(parser)\n",
    "    args, unknown = parser.parse_known_args(user_args)\n",
    "    print(\"Base CLI args: \")\n",
    "    pprint(args)\n",
    "\n",
    "    # ------------------------------------------------------------------------\n",
    "    # Add model/datamodule/trainer specific args\n",
    "    # ------------------------------------------------------------------------\n",
    "    model_class = get_model_class(args.model_name)\n",
    "    dm_class = get_dm_class(args.data_name)\n",
    "    parser = model_class.add_model_specific_args(parser)\n",
    "    parser = dm_class.add_model_specific_args(parser)\n",
    "    parser = pl.Trainer.add_argparse_args(parser)\n",
    "\n",
    "    # RayTune args\n",
    "    parser.add_argument('--n_cpus',  type=int, default=8, help='Num of CPUs per trial')\n",
    "    parser.add_argument(\"--gpu_ids\", type=str, required=True, nargs='*',\n",
    "                        help=\"GPU ID(s) to use\") #Returns an empty list if not specified\n",
    "    parser.add_argument(\"--n_ray_samples\", type=int, default=1,\n",
    "                         help=\"Num of Ray Tune's run argument, num_samples\")\n",
    "    parser.add_argument(\"--ray_log_dir\", type=str, default=\"/data/log/ray\",\n",
    "                        help=\"dir to save training results from Ray\")\n",
    "    # Callback switch args\n",
    "    parser = BetaScheduler.add_argparse_args(parser)\n",
    "    # parser.add_argument(\"--hist_epoch_interval\", type=int, default=10, help=\"Epoch interval to plot histogram of q's parameter\")\n",
    "    # parser.add_argument(\"--recon_epoch_interval\", type=int, default=10, help=\"Epoch interval to plot reconstructions of train and val samples\")\n",
    "    args = parser.parse_args(user_args)\n",
    "    print(\"Final args: \")\n",
    "    pprint(args)\n",
    "\n",
    "    # Select Visible GPU\n",
    "    os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = ','.join(args.gpu_ids)\n",
    "    print(\"===GPUs===\")\n",
    "    print(os.environ[\"CUDA_VISIBLE_DEVICES\"])\n",
    "\n",
    "    def set_hparam_and_train_closure(config: Dict[str, Any]):\n",
    "        \"\"\"Use the (k,v) in `overwrite` to update the args\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        config: Hyperparam search space as a Dict[hparam-name, value of the hpamram]\n",
    "            This dict object is a sample point from the Ray's Hyperparameter space,\n",
    "            and will be used to overwrite the `args`'s key-value with its key-value.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        None. Train the model in the specified hyperparmeter space\n",
    "        \"\"\"\n",
    "        print(\"Inside the clousure===\")\n",
    "        pprint(args)\n",
    "        print(\"===\")\n",
    "        pprint(config)\n",
    "\n",
    "        d_args =  vars(args)\n",
    "        for k, v in config.items():\n",
    "            d_args[k] = v\n",
    "            print(\"Overwrote args: \", k)\n",
    "\n",
    "        # Start experiment with this overwritten hyperparams\n",
    "        train_tune(args)\n",
    "\n",
    "    # ------------------------------------------------------------------------\n",
    "    # Specify hyperparameter search space\n",
    "    # ------------------------------------------------------------------------\n",
    "    search_space = {\n",
    "        # \"latent_dim\": tune.grid_search([10, 20, 60, 100]),\n",
    "        'enc_type': tune.choice(['conv', 'resnet']),\n",
    "        'dec_type': tune.choice(['conv', 'resnet']),\n",
    "        'is_contrasive': tune.choice([False, True]),\n",
    "        'kld_weight': tune.choice(np.array([0.5*(2**i) for i in range(12)])), #[0.5, 1.0, 2.0, 4.0, 8.0, 16.0, 32., 64, 128., 256, 512, 1024]), #np.array([0.5*(2**i) for i in range(12)])\n",
    "        'use_beta_scheduler': False, #tune.grid_search([False,True]),\n",
    "        'adv_loss_weight': tune.choice(np.logspace(0.0, 7.0, num=8, base=3.0)),\n",
    "        'learning_rate': tune.loguniform(1e-4, 1e-1), #tune.grid_search(list(np.logspace(-4., -1, num=10))),\n",
    "        'batch_size': tune.choice([32, 64, 128,]),\n",
    "    }\n",
    "    \n",
    "\n",
    "    # ------------------------------------------------------------------------\n",
    "    # Start hyperparameter search using Ray\n",
    "    # ------------------------------------------------------------------------\n",
    "    ray.shutdown()\n",
    "    ray.init(log_to_driver=False)\n",
    "    # search_alg =\n",
    "\n",
    "    reporter = CLIReporter(\n",
    "        parameter_columns=list(search_space.keys()),\n",
    "        metric_columns=[\"loss\", \"mean_accuracy\", \"training_iteration\"])\n",
    "    \n",
    "#     breakpoint()\n",
    "    \n",
    "    analysis = tune.run(\n",
    "        set_hparam_and_train_closure,\n",
    "        config=search_space,\n",
    "        metric='loss', #set to val_loss\n",
    "        mode='min',\n",
    "        # search_alg=search_alg,\n",
    "        num_samples=args.n_ray_samples,\n",
    "        verbose=1,\n",
    "        progress_reporter=reporter,\n",
    "        name=\"Tune-BiVAE\", # name of experiment\n",
    "        local_dir= args.ray_log_dir,\n",
    "        resources_per_trial={\"cpu\":args.n_cpus, \"gpu\": len(args.gpu_ids)}, # there are 16cpus in arya machine; so at a time 16/2=8 trials will be run concurrently\n",
    "    )\n",
    "    print(\"Best hyperparameters found were: \", analysis.best_config)\n",
    "\n",
    "    dfs = analysis.fetch_trial_dataframes()\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "#         # Debug\n",
    "#     config = {\n",
    "#         # \"latent_dim\": tune.grid_search([10, 20, 60, 100]),\n",
    "#         'enc_type': 'conv',\n",
    "#         'dec_type': 'resnet',\n",
    "#         'is_contrasive': False,\n",
    "#         'kld_weight': 1.0, \n",
    "#         'use_beta_scheduler': False, #tune.grid_search([False,True]),\n",
    "#         'adv_loss_weight': 1.0, \n",
    "#         'learning_rate': 1e-4, \n",
    "#         'batch_size': 32,\n",
    "#     }\n",
    "#     set_hparam_and_train_closure(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "traditional-representative",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmd = \"\"\"--model_name bivae \n",
    "--latent_dim 20 \n",
    "--hidden_dims 32 64 128 256 512 \n",
    "--adv_dim 32 32 32 \n",
    "--data_name \"multi_maptiles\" \n",
    "--cities 'la' 'charlotte' 'vegas' 'boston' 'paris' 'amsterdam' 'shanghai' 'seoul' 'chicago' 'manhattan' 'berlin' 'montreal' 'rome' \n",
    "--styles StamenTonerBackground --n_styles 1 \n",
    "--zooms 14 \n",
    "--gpu_ids 0 --max_epochs 150 --terminate_on_nan True \n",
    "--n_ray_samples 1 \n",
    "--log_root \"/data/hayley-old/Tenanbaum2000/lightning_logs/2021-03-08-ray/\"\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "valuable-ghost",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_args = cmd.replace('\\n', '').replace('\"', '').replace('\\'', '').split(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "public-family",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(user_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rapid-reproduction",
   "metadata": {},
   "outputs": [],
   "source": [
    "main(user_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recorded-apartment",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "checked-night",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "monetary-contamination",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "noticed-fortune",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "voluntary-malpractice",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acquired-aurora",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "outer-sample",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_args = cmd.replace('\\n', '').replace('\"', '').replace('\\'', '').split(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "received-senegal",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(user_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "simplified-addiction",
   "metadata": {},
   "outputs": [],
   "source": [
    "main(user_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "genetic-participant",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "conscious-missile",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "waiting-monkey",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "analyzed-recipient",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unlimited-prince",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "foreign-exhibit",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "divine-forth",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "republican-dining",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "american-proof",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "applicable-persian",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "further-wagon",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "falling-valley",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "minor-policy",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "increased-store",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "enormous-brass",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "marine-advantage",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "frequent-illinois",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "opened-teacher",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "measured-disorder",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "military-holiday",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unavailable-cycle",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reasonable-origin",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "headed-supply",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "occupied-aurora",
   "metadata": {},
   "outputs": [],
   "source": [
    "from argparse import Namespace\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "trained-voice",
   "metadata": {},
   "outputs": [],
   "source": [
    "# args=Namespace(\n",
    "#   act_fn='leaky_relu', \n",
    "#   adv_loss_weight=1.0, \n",
    "#   adversary_dims=[32, 32, 32], \n",
    "#   batch_size=32, \n",
    "#    cities=['la', 'charlotte', 'vegas', 'boston', 'paris', 'amsterdam', 'shanghai', 'seoul', 'chicago', 'manhattan', 'berlin', 'montreal', 'rome'],\n",
    "#     data_name='multi_maptiles', \n",
    "#     data_root='/data/hayley-old/maptiles_v2/', \n",
    "#     dec_type='conv', default_root_dir=None, \n",
    "#     enc_type='conv', \n",
    "#     gpu_ids=['0'], \n",
    "#     hidden_dims=[32, 64, 128, 256, 512], \n",
    "#     in_shape=[3, 32, 32], \n",
    "#     is_contrasive=True, \n",
    "#     kld_weight=1.0, \n",
    "#     latent_dim=20, learning_rate=0.001,  \n",
    "#     log_root='/data/hayley-old/Tenanbaum2000/lightning_logs/2021-03-08-ray/', \n",
    "#     logger=True, \n",
    "#     max_epochs=150,\n",
    "#     mode='fit', \n",
    "#     model_name='bivae',\n",
    "#     n_cpus=8, n_ray_samples=1, n_styles=1, \n",
    "#     ray_log_dir='/data/log/ray',\n",
    "#     styles=['StamenTonerBackground'], \n",
    "#     terminate_on_nan=True, \n",
    "#     use_beta_scheduler=True,\n",
    "#     pin_memory=True,\n",
    "#     num_workers=16,\n",
    "#     verbose=False,\n",
    "#     zooms=['14'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "occasional-tulsa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# debug\n",
    "# train_tune(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bronze-worry",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:test]",
   "language": "python",
   "name": "conda-env-test-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
