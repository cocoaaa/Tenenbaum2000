{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adversarial VAE (Adv.VAE)\n",
    "- Dec 31, 2020\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,sys\n",
    "import re\n",
    "import math\n",
    "from datetime import datetime\n",
    "import time\n",
    "sys.dont_write_bytecode = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pathlib import Path\n",
    "from typing import List, Set, Dict, Tuple, Optional, Iterable, Mapping, Union, Callable, TypeVar\n",
    "\n",
    "from pprint import pprint\n",
    "from ipdb import set_trace as brpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from  torch.linalg import norm as tnorm\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.core.lightning import LightningModule\n",
    "from pytorch_lightning import loggers as pl_loggers\n",
    "from pytorch_lightning.tuner.tuning import Tuner\n",
    "\n",
    "\n",
    "# Select Visible GPU\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\" \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Path \n",
    "1. Add project root and src folders to `sys.path`\n",
    "2. Set DATA_ROOT to `maptile_v2` folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "this_nb_path = Path(os.getcwd())\n",
    "ROOT = this_nb_path.parent\n",
    "SRC = ROOT/'src'\n",
    "DATA_ROOT = Path(\"/data/hayley-old/maptiles_v2/\")\n",
    "paths2add = [this_nb_path, ROOT]\n",
    "\n",
    "print(\"Project root: \", str(ROOT))\n",
    "print('Src folder: ', str(SRC))\n",
    "print(\"This nb path: \", str(this_nb_path))\n",
    "\n",
    "\n",
    "for p in paths2add:\n",
    "    if str(p) not in sys.path:\n",
    "        sys.path.insert(0, str(p))\n",
    "        print(f\"\\n{str(p)} added to the path.\")\n",
    "        \n",
    "# print(sys.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data.transforms.transforms import Identity, Unnormalizer, LinearRescaler\n",
    "from src.data.transforms.functional import unnormalize\n",
    "\n",
    "from src.visualize.utils import show_timgs, show_batch\n",
    "from src.utils.misc import info\n",
    "from collections import OrderedDict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start experiment \n",
    "Given a maptile, predict its style as one of OSM, CartoVoyager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models.plmodules.vanilla_vae import VanillaVAE\n",
    "from src.models.plmodules.bilatent_vae import BiVAE\n",
    "from src.models.plmodules.three_fcs import ThreeFCs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # For reproducibility, set seed like following:\n",
    "# seed = 100\n",
    "# pl.seed_everything(seed)\n",
    "# # sets seeds for numpy, torch, python.random and PYTHONHASHSEED.\n",
    "# model = Model()\n",
    "# trainer = pl.Trainer(deterministic=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adversarial model\n",
    "\n",
    "TODO:\n",
    "\n",
    "---\n",
    "### For batch in dataloader:\n",
    "- x: (BS, C, h, w): a mini-batch of (c,h,w) tensor\n",
    "\n",
    "### mu, log_var = model.encoder(x) \n",
    "- mu: (BS, latent_dim)\n",
    "- log_var: (BS, latent_dim)\n",
    "\n",
    "### z = model.rsample(mu, log_var, self.n_samples) \n",
    "- z: (BS, n_samples, latent_dim)\n",
    "-`z[n]` constains `n_samples` number of latent codes, sampled from the same distribution `N(mu[n], logvar[n])`\n",
    " \n",
    "### recon = model.decoder(z) \n",
    "- recon: (BS, n_samples, c, h, w)\n",
    "- `recon[n]` contains `n_samples` number of (c,h,w)-sized $mu_{x}$, corresponding to the center of the factorized Gaussian for the latent code $z^{(n,l)}$ ($l$th z_sample from $N(\\mu[n], logvar[n])$, ie. $\\mu_{x}^{(n,l)}$\n",
    "\n",
    "### out = model.forward(x)\n",
    "- out (dict): keys are \"mu\", \"logvar\", \"recon\"\n",
    "\n",
    "### loss_dict = loss_function(out, x, self.n_samples)\n",
    "- loss_dict (dict): keys are \"loss\", \"kl\", \"recon_loss\"\n",
    "- kl is computed the same way as in the Vanillia_VAE model's `loss_function`\n",
    "- recon_loss is a generalized version with `self.n_samples` (>=1) number of samples to estimated each datapoint's MSE_loss as the average over the loss's from the `n_samples` number of $z_{n,l}$ samples.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data.datamodules import BaseDataModule, USPSDataModule, MNISTMDataModule, MNISTDataModule\n",
    "from src.models.plmodules.bilatent_vae import BiVAE\n",
    "\n",
    "# Init DataModule\n",
    "data_root = ROOT/'data'\n",
    "in_shape = (1,32,32)\n",
    "batch_size = 32\n",
    "\n",
    "dm = MNISTDataModule(\n",
    "    data_root=data_root, \n",
    "    in_shape=in_shape,\n",
    "    batch_size=batch_size)\n",
    "dm.setup('fit')\n",
    "# show_batch(dm, cmap='gray')\n",
    "\n",
    "# Initi plModule\n",
    "latent_dim=10\n",
    "hidden_dims = [32,64,128,256]#,512]\n",
    "adversary_dims = [30,20,15]\n",
    "lr = 1e-3\n",
    "act_fn = nn.ReLU()\n",
    "is_contrasive = True # If true, use adv. loss from both content and style codes. Else just style codes\n",
    "model = BiVAE(\n",
    "    in_shape=dm.size(), \n",
    "    n_classes=dm.n_classes,\n",
    "    latent_dim=latent_dim,\n",
    "    hidden_dims=hidden_dims,\n",
    "    adversary_dims=adversary_dims,\n",
    "    learning_rate=lr, \n",
    "    act_fn=act_fn,\n",
    "    size_average=False\n",
    ")\n",
    "\n",
    "# model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add Callbacks\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "from src.callbacks.hist_logger import HistogramLogger\n",
    "from src.callbacks.recon_logger import ReconLogger\n",
    "\n",
    "# Model wrapper from graph viz\n",
    "from src.models.model_wrapper import ModelWrapper\n",
    "\n",
    "callbacks = [\n",
    "#         HistogramLogger(hist_epoch_interval=1),\n",
    "#         ReconLogger(recon_epoch_interval=1),\n",
    "#         EarlyStopping('val_loss', patience=10),\n",
    "]\n",
    "\n",
    "# Start the experiment\n",
    "exp_name = f'{model.name}_{dm.name}'\n",
    "tb_logger = pl_loggers.TensorBoardLogger(save_dir=f'{ROOT}/temp-logs', \n",
    "                                         name=exp_name,\n",
    "                                         log_graph=False,\n",
    "                                        default_hp_metric=False)\n",
    "print(tb_logger.log_dir)\n",
    "\n",
    "# Log computational graph\n",
    "# model_wrapper = ModelWrapper(model)\n",
    "# tb_logger.experiment.add_graph(model_wrapper, model.example_input_array.to(model.device))\n",
    "# tb_logger.log_graph(model)\n",
    "\n",
    "trainer_config = {\n",
    "    'gpus':1,\n",
    "    'max_epochs': 300,\n",
    "    'progress_bar_refresh_rate':20,\n",
    "#     'auto_lr_find': True,\n",
    "    'terminate_on_nan':True,\n",
    "#     'num_sanity_val_steps':0.25,\n",
    "    'check_val_every_n_epoch':10,\n",
    "    'logger':tb_logger,\n",
    "#     'callbacks':callbacks,\n",
    "}\n",
    "\n",
    "# \n",
    "# trainer = pl.Trainer(fast_dev_run=3)\n",
    "trainer = pl.Trainer(**trainer_config)\n",
    "# trainer.tune(model=model, datamodule=dm)\n",
    "\n",
    "# Start exp\n",
    "# Fit model\n",
    "trainer.fit(model, dm)\n",
    "print(f\"Finished at ep {trainer.current_epoch, trainer.batch_idx}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " TODO:\n",
    " OPTIMIZER\n",
    " def configure_optimizers(self):\n",
    "        #TODO: ADD optimizer for discriminator\n",
    "        return torch.optim.Adam(self.parameters(), lr=self.hparams.get(\"learning_rate\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO:\n",
    "- [ ] Check output sizes of BiVAE's \n",
    "    - [x] encode\n",
    "    - [x] rsample\n",
    "    - [x] combine_content_and_style\n",
    "    - [x] decode\n",
    "    - [x] forward\n",
    "- [ ] Check losses "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = next(iter(dm.train_dataloader()))\n",
    "info(x), info(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- check `encode` and `rsample`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_qparams = model.encode(x)\n",
    "for k,v in dict_qparams.items():\n",
    "    print(f\"\\n{k}:  {v.shape}\")\n",
    "    if 'mu' in k:\n",
    "        print(v[0])\n",
    "    else:\n",
    "        print(v[0].exp())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_z = model.rsample(dict_qparams)\n",
    "for k,v in dict_z.items():\n",
    "    print(f\"\\n{k}:  {v.shape}\")\n",
    "    print(v[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- check `combine_content_style` and `decode`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = model.combine_content_style(dict_z)\n",
    "assert z.shape == (batch_size, latent_dim)\n",
    "print(\"z shape: \", z.shape) #(BS, latent_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu_x_pred = model.decode(z)\n",
    "assert mu_x_pred.shape == (batch_size, *in_shape)\n",
    "print(\"mu_x_pred shape: \", mu_x_pred.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Check the entire forward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dict  = model(x)\n",
    "for k,v in out_dict.items():\n",
    "    print(f\"\\n{k}:  {v.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Check the component's of the optimization objective (ie. loss)\n",
    "    - [x] partition_z: z -> dict_z (keys are \"c\" and \"s\")\n",
    "    - [ ] predict_y: z_partition -> scores\n",
    "    - [ ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_z = model.partition_z(z)\n",
    "for k,v in dict_z.items():\n",
    "    print(f\"{k}: {v.shape}\")\n",
    "    assert v.shape == (batch_size, model.content_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c,s = dict_z[\"c\"], dict_z[\"s\"]\n",
    "c.shape, s.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: \n",
    "- [ ] Showing the changes in the scores based on c and scores based on s will be super intersting to see as the model learns!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_c = model.predict_y(c)\n",
    "scores_s = model.predict_y(s)\n",
    "assert scores_c.shape == (batch_size, model.n_classes)\n",
    "assert scores_s.shape == (batch_size, model.n_classes)\n",
    "\n",
    "print(scores_c[0]) # TODO: Showing the changes in the scores based on c and scores based on s will be super intersting to see as the model learns!!!\n",
    "print(scores_s[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- check `compute_loss_c` and `compute_loss_s`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_c = model.compute_loss_c(c)\n",
    "print(\"loss_c: \", loss_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_s = model.compute_loss_s(s, y)\n",
    "print(\"loss_s: \", loss_s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Full loss workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dict = model(x)\n",
    "loss_dict = model.loss_function(out_dict, [x,y], 'train')\n",
    "pprint(loss_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.ones((5,2))\n",
    "b = torch.zeros((5,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cat([a,b], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = nn.LogSoftmax()\n",
    "m(a).exp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO: \n",
    "Showing the changes in the scores based on c and scores based on s will be super intersting to see as the model learns!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Play with MNISTM and USPS datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- MNISTM\n",
    "    - original size of an image: (1, 16,16)\n",
    "    - labels: {0, ..., 9}\n",
    "- USPS\n",
    "    - original size of an image: (3, 28, 28)\n",
    "    - labels\" {0, ..., 9}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data.datasets.mnistm import MNISTM\n",
    "from torchvision.datasets import USPS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNISTM Dataset\n",
    "bs = 16\n",
    "num_workers = 16\n",
    "pin_memory = True\n",
    "xforms = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    ])\n",
    "# target_xforms = \n",
    "ds = MNISTM(ROOT/'data', \n",
    "          transform=xforms,\n",
    "          download=True)\n",
    "\n",
    "dl = DataLoader(ds, batch_size=bs, shuffle=True, \n",
    "               num_workers=num_workers, pin_memory=pin_memory)\n",
    "\n",
    "\n",
    "x,y = next(iter(dl))\n",
    "info(x)\n",
    "info(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_timgs(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# USPS Dataset\n",
    "bs = 16\n",
    "num_workers = 16\n",
    "pin_memory = True\n",
    "xforms = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    ])\n",
    "# target_xforms = \n",
    "ds = USPS(ROOT/'data', \n",
    "          transform=xforms,\n",
    "          download=True)\n",
    "\n",
    "dl = DataLoader(ds, batch_size=bs, shuffle=True, \n",
    "               num_workers=num_workers, pin_memory=pin_memory)\n",
    "\n",
    "\n",
    "x,y = next(iter(dl))\n",
    "info(x)\n",
    "info(y)\n",
    "show_timgs(x, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:test]",
   "language": "python",
   "name": "conda-env-test-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
