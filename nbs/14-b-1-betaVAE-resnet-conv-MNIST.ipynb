{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,sys\n",
    "import re\n",
    "import math\n",
    "from datetime import datetime\n",
    "import time\n",
    "sys.dont_write_bytecode = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.color import rgb2gray\n",
    "from skimage.transform import resize\n",
    "\n",
    "from pathlib import Path\n",
    "from typing import List, Set, Dict, Tuple, Optional, Iterable, Mapping, Union, Callable\n",
    "\n",
    "from pprint import pprint\n",
    "from ipdb import set_trace as brpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from  torch.linalg import norm as tnorm\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.core.lightning import LightningModule\n",
    "from pytorch_lightning import loggers as pl_loggers\n",
    "# Select Visible GPU\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"2\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Path \n",
    "1. Add project root and src folders to `sys.path`\n",
    "2. Set DATA_ROOT to `maptile_v2` folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root:  /data/hayley-old/Tenanbaum2000\n",
      "Src folder:  /data/hayley-old/Tenanbaum2000/src\n",
      "This nb path:  /data/hayley-old/Tenanbaum2000/nbs\n",
      "\n",
      "/data/hayley-old/Tenanbaum2000 added to the path.\n"
     ]
    }
   ],
   "source": [
    "this_nb_path = Path(os.getcwd())\n",
    "ROOT = this_nb_path.parent\n",
    "SRC = ROOT/'src'\n",
    "DATA_ROOT = Path(\"/data/hayley-old/maptiles_v2/\")\n",
    "paths2add = [this_nb_path, ROOT]\n",
    "\n",
    "print(\"Project root: \", str(ROOT))\n",
    "print('Src folder: ', str(SRC))\n",
    "print(\"This nb path: \", str(this_nb_path))\n",
    "\n",
    "\n",
    "for p in paths2add:\n",
    "    if str(p) not in sys.path:\n",
    "        sys.path.insert(0, str(p))\n",
    "        print(f\"\\n{str(p)} added to the path.\")\n",
    "        \n",
    "# print(sys.path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from src.data.datasets.maptiles import Maptiles, MapStyles\n",
    "from src.data.datamodules.mnist_datamodule import MNISTDataModule\n",
    "from src.data.datamodules.maptiles_datamodule import MaptilesDataModule\n",
    "\n",
    "from src.models.plmodules.three_fcs import ThreeFCs\n",
    "from src.models.plmodules.vanilla_vae import VanillaVAE\n",
    "from src.models.plmodules.beta_vae import BetaVAE\n",
    "\n",
    "from src.visualize.utils import show_timgs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start experiment \n",
    "Given a maptile, predict its style as one of OSM, CartoVoyager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DM:  MNIST\n"
     ]
    }
   ],
   "source": [
    "# Instantiate MNIST Datamodule\n",
    "in_shape = (1,32,32)\n",
    "batch_size = 32\n",
    "dm = MNISTDataModule(data_root=ROOT/'data', \n",
    "                       in_shape=in_shape,\n",
    "                      batch_size=batch_size)\n",
    "dm.setup('fit')\n",
    "print(\"DM: \", dm.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Instantiate data module\n",
    "# all_cities = ['la', 'charlotte', 'vegas', 'boston', 'paris', \\\n",
    "#               'amsterdam', 'shanghai', 'seoul', 'chicago', 'manhattan', \\\n",
    "#              'berlin', 'montreal', 'rome']\n",
    "# cities = all_cities #['berlin']#['paris']\n",
    "# styles = ['StamenTonerBackground']#['OSMDefault', 'CartoVoyagerNoLabels']\n",
    "# zooms = ['14']\n",
    "# in_shape = (1, 64, 64)\n",
    "# batch_size = 32\n",
    "# dm = MaptilesDataModule(data_root=DATA_ROOT,\n",
    "#                         cities=cities,\n",
    "#                         styles=styles,\n",
    "#                         zooms=zooms,\n",
    "#                        in_shape=in_shape,\n",
    "#                        batch_size=batch_size\n",
    "#                        )\n",
    "# dm.setup('fit')\n",
    "# print(\"DM: \", dm.name)\n",
    "\n",
    "# # Instantiate the pl Module\n",
    "# latent_dim = 10\n",
    "# hidden_dims = [32,64,128,256,512]\n",
    "# act_fn = nn.LeakyReLU()\n",
    "# learning_rate = 3e-4\n",
    "# model = VanillaVAE(\n",
    "#     in_shape=in_shape,\n",
    "#     latent_dim=latent_dim,\n",
    "#     hidden_dims=hidden_dims,\n",
    "#     learning_rate=learning_rate,\n",
    "#     act_fn=act_fn\n",
    "# )\n",
    "# print(model.hparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the pl Module\n",
    "from src.models.plmodules.beta_vae import BetaVAE\n",
    "\n",
    "betas = [0.1 * 3**i for i in range(10)]\n",
    "# for kld_weight in [1.0]\n",
    "latent_dim = 10\n",
    "hidden_dims = [32, 64, 128, 256] #,512]\n",
    "act_fn = nn.LeakyReLU()\n",
    "learning_rate = 3e-4\n",
    "kld_weight = 1.0 #betas[0]\n",
    "enc_type = 'resnet'\n",
    "# dec_type = 'conv'\n",
    "dec_type = 'conv'\n",
    "\n",
    "if enc_type == 'resnet':\n",
    "    hidden_dims = [32, 32, 64, 128, 256]\n",
    "\n",
    "model = BetaVAE(\n",
    "    in_shape=in_shape, \n",
    "    latent_dim=latent_dim,\n",
    "    hidden_dims=hidden_dims,\n",
    "    learning_rate=learning_rate,\n",
    "    act_fn=act_fn,\n",
    "    kld_weight=kld_weight,\n",
    "    enc_type=enc_type,\n",
    "    dec_type=dec_type,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'BetaVAE-resnet-conv-1.000'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log dir:  /data/hayley-old/Tenanbaum2000/temp-logs/BetaVAE-resnet-conv-1.000_MNIST/version_0\n",
      "Created:  /data/hayley-old/Tenanbaum2000/temp-logs/BetaVAE-resnet-conv-1.000_MNIST/version_0\n"
     ]
    }
   ],
   "source": [
    "# Instantiate a PL `Trainer` object\n",
    "# Start the experiment\n",
    "max_epochs = 200\n",
    "exp_name = f'{model.name}_{dm.name}'\n",
    "tb_logger = pl_loggers.TensorBoardLogger(save_dir=f'{ROOT}/temp-logs', \n",
    "                                         name=exp_name,\n",
    "                                         log_graph=False,\n",
    "                                        default_hp_metric=False)\n",
    "print(\"Log dir: \", tb_logger.log_dir)\n",
    "\n",
    "log_dir = Path(tb_logger.log_dir)\n",
    "if not log_dir.exists():\n",
    "    log_dir.mkdir(parents=True)\n",
    "    print(\"Created: \", log_dir)\n",
    "    \n",
    "\n",
    "# Log computational graph\n",
    "# model_wrapper = ModelWrapper(model)\n",
    "# tb_logger.experiment.add_graph(model_wrapper, model.example_input_array.to(model.device))\n",
    "# tb_logger.log_graph(model)\n",
    "\n",
    "trainer_config = {\n",
    "    'gpus':1,\n",
    "    'max_epochs': max_epochs,\n",
    "    'progress_bar_refresh_rate':0,\n",
    "    'terminate_on_nan':True,\n",
    "    'check_val_every_n_epoch':10,\n",
    "    'logger':tb_logger,\n",
    "#     'callbacks':callbacks,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BetaVAE is called\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name              | Type       | Params | In sizes        | Out sizes      \n",
      "-------------------------------------------------------------------------------------\n",
      "0 | act_fn            | LeakyReLU  | 0      | [1, 32, 16, 16] | [1, 32, 16, 16]\n",
      "1 | out_fn            | Tanh       | 0      | [1, 1, 32, 32]  | [1, 1, 32, 32] \n",
      "2 | encoder           | ResNet     | 2.8 M  | [1, 1, 32, 32]  | [1, 256, 2, 2] \n",
      "3 | fc_mu             | Linear     | 10.2 K | [1, 1024]       | [1, 10]        \n",
      "4 | fc_var            | Linear     | 10.2 K | [1, 1024]       | [1, 10]        \n",
      "5 | fc_latent2flatten | Linear     | 11.3 K | [1, 10]         | [1, 1024]      \n",
      "6 | decoder           | Sequential | 388 K  | [1, 256, 2, 2]  | [1, 1, 32, 32] \n",
      "7 | out_layer         | Sequential | 10     | [1, 1, 32, 32]  | [1, 1, 32, 32] \n",
      "-------------------------------------------------------------------------------------\n",
      "3.2 M     Trainable params\n",
      "0         Non-trainable params\n",
      "3.2 M     Total params\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep: 0, batch: 0, loss: 31734.501953125\n",
      "Ep: 0, batch: 0, loss: 32631.783203125\n"
     ]
    }
   ],
   "source": [
    "# trainer = pl.Trainer(fast_dev_run=3)\n",
    "trainer = pl.Trainer(**trainer_config)\n",
    "# trainer.tune(model=model, datamodule=dm)\n",
    "\n",
    "# Fit model\n",
    "trainer.fit(model, dm)\n",
    "print(f\"Finished at ep {trainer.current_epoch, trainer.batch_idx}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ResNet Encoder\n",
    "- Jan 27, 2021\n",
    "- https://d2l.ai/chapter_convolutional-modern/resnet.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Residual_V1(nn.Module):\n",
    "    \"\"\"A module that implements a single flow of residual operation for ResNet.\n",
    "    Each conv layer uses kernel of size 3x3, stride=streids, and padding=1.\n",
    "    First the input's (h,w) are shrinked by `stride`, then the num of channels\n",
    "    is increased to out_c via subsequent conv operations.\n",
    "    \n",
    "    \n",
    "    input ---> conv2d-bn-relu -> z1 ---> conv2d-bn-----> z2 -> relu -> out\n",
    "            |                                            ^\n",
    "            |                                            |\n",
    "            |                                            +\n",
    "            ----------------->(1x1 conv2d)----------------\n",
    "    \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    stride : int\n",
    "        Stride parameter of the first conv layer. Use stride = 2 as a way to \n",
    "        halve the width, height of the input; similar to applying a pooling \n",
    "        operation.  \n",
    "        \n",
    "        \n",
    "    use_1x1conv : bool\n",
    "        Applies the 1x1 conv to the input to match the input's n_channel (in_c)\n",
    "        to be equal to the output's n_chhanel (out_c), as well as (h,w) adjustment\n",
    "        by `stride`.\n",
    "        \n",
    "        It must be set to True when the input's num channel or (h,w) need to \n",
    "        be adjusted in order to be added to the second conv's output (z2), ie: \n",
    "        - in_c is different from out_c, or\n",
    "        - `stride` != 1, or\n",
    "        - same shape of input and output, but just want to add 1x1 conv operation\n",
    "        to the input before adding it to the activation after the second conv.\n",
    "        \n",
    "    `forward(x)` returns\n",
    "    -----------\n",
    "    out = model(x) returns a batch of tensors whose size is :\n",
    "        (BS, out_c, in_h/stride, in_w/stride)\n",
    "        \n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, in_c, out_c, \n",
    "                 *,\n",
    "                 stride=1,\n",
    "                use_1x1conv=False, \n",
    "                act_fn=nn.ReLU(inplace=True),\n",
    "                kernel_size=3, padding=1 ):\n",
    "        super().__init__()\n",
    "        self.stride = stride\n",
    "        self.use_1x1conv = use_1x1conv\n",
    "        self.conv1 = nn.Conv2d(in_c, out_c, \n",
    "                              kernel_size=kernel_size, padding=padding, stride=self.stride)\n",
    "        self.bn1 = nn.BatchNorm2d(out_c)\n",
    "        self.conv2 = nn.Conv2d(out_c, out_c,\n",
    "                              kernel_size=kernel_size, padding=padding, stride=1)\n",
    "        self.bn2 = nn.BatchNorm2d(out_c)\n",
    "        \n",
    "        self.conv3 = None\n",
    "        if use_1x1conv:\n",
    "            self.conv3 = nn.Conv2d(in_c, out_c,\n",
    "                                  kernel_size=1, padding=0, stride=self.stride)\n",
    "        self.act_fn = act_fn\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Returns\n",
    "        -------\n",
    "        out = model(x) returns a batch of tensors whose size is :\n",
    "        (BS, out_c, in_h/stride, in_w/stride)\n",
    "        \n",
    "        \"\"\"\n",
    "        z = self.act_fn(self.bn1(self.conv1(x)))\n",
    "        z = self.bn2(self.conv2(z))\n",
    "        \n",
    "        if self.use_1x1conv:\n",
    "            x = self.conv3(x)\n",
    "        z = z + x\n",
    "        return self.act_fn(z)\n",
    "            \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Residual(nn.Module):\n",
    "    \"\"\"A module that implements a single flow of residual operation for ResNet.\n",
    "    Each conv layer uses kernel of size 3x3, stride=streids, and padding=1.\n",
    "    First the input's (h,w) are shrinked by `stride`, then the num of channels\n",
    "    is increased to out_c via subsequent conv operations.\n",
    "    \n",
    "    \n",
    "    input ---> (bn-relu-conv2d) -> z1 ---> (bn-relu-conv2d) -> z2 ---> out\n",
    "            |                                                   ^\n",
    "            |                                                   |\n",
    "            |                                                   +\n",
    "            ----------------->  (1x1 conv2d) --------------------\n",
    "    \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    stride : int\n",
    "        Stride parameter of the first conv layer. Use stride = 2 as a way to \n",
    "        halve the width, height of the input; similar to applying a pooling \n",
    "        operation.  \n",
    "        \n",
    "        \n",
    "    use_1x1conv : bool\n",
    "        Applies the 1x1 conv to the input to match the input's n_channel (in_c)\n",
    "        to be equal to the output's n_chhanel (out_c), as well as (h,w) adjustment\n",
    "        by `stride`.\n",
    "        \n",
    "        It must be set to True when the input's num channel or (h,w) need to \n",
    "        be adjusted in order to be added to the second conv's output (z2), ie: \n",
    "        - in_c is different from out_c, or\n",
    "        - `stride` != 1, or\n",
    "        - same shape of input and output, but just want to add 1x1 conv operation\n",
    "        to the input before adding it to the activation after the second conv.\n",
    "        \n",
    "    `forward(x)` returns\n",
    "    -----------\n",
    "    out = model(x) returns a batch of tensors whose size is :\n",
    "        (BS, out_c, in_h/stride, in_w/stride)\n",
    "        \n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, in_c, out_c, \n",
    "                 *,\n",
    "                 stride=1,\n",
    "                 use_1x1conv=False, \n",
    "                 act_fn=nn.ReLU(inplace=True),\n",
    "                 kernel_size=3, \n",
    "                 padding=1):\n",
    "        super().__init__()\n",
    "        self.stride = stride\n",
    "        self.use_1x1conv = use_1x1conv\n",
    "        \n",
    "        self.bn1 = nn.BatchNorm2d(in_c)\n",
    "        self.conv1 = nn.Conv2d(in_c, out_c, \n",
    "                              kernel_size=kernel_size, padding=padding, stride=self.stride)\n",
    "        \n",
    "        self.bn2 = nn.BatchNorm2d(out_c)\n",
    "        self.conv2 = nn.Conv2d(out_c, out_c,\n",
    "                              kernel_size=kernel_size, padding=padding, stride=1)\n",
    "        \n",
    "        self.conv3 = None\n",
    "        if use_1x1conv:\n",
    "            self.conv3 = nn.Conv2d(in_c, out_c,\n",
    "                                  kernel_size=1, padding=0, stride=self.stride)\n",
    "        self.act_fn = act_fn\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Returns\n",
    "        -------\n",
    "        out = model(x) returns a batch of tensors whose size is :\n",
    "        (BS, out_c, in_h/stride, in_w/stride)\n",
    "        \n",
    "        \"\"\"\n",
    "        z = self.conv1(self.act_fn(self.bn1(x)))\n",
    "        z = self.conv2(self.act_fn(self.bn2(z)))\n",
    "        \n",
    "        if self.use_1x1conv:\n",
    "            x = self.conv3(x)\n",
    "        z = z + x\n",
    "        return self.act_fn(z)\n",
    "            \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Residual: in_c --> out_c is not the same\n",
    "in_shape = (3, 64,64)\n",
    "in_c = in_shape[0]\n",
    "out_c = 32\n",
    "stride = 2\n",
    "m = Residual(in_c, out_c, \n",
    "             use_1x1conv=True, \n",
    "            stride=stride)\n",
    "\n",
    "\n",
    "x = torch.ones(1,*in_shape)\n",
    "out = m(x)\n",
    "\n",
    "print(x.shape, out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Residual: in_c --> out_c is the same\n",
    "in_shape = (32, 8, 8)\n",
    "in_c = in_shape[0]\n",
    "out_c = in_c\n",
    "stride = 2\n",
    "\n",
    "m = Residual(in_c, out_c, \n",
    "             use_1x1conv=True, \n",
    "             stride=stride)\n",
    "\n",
    "\n",
    "x = torch.ones(1,*in_shape)\n",
    "out = m(x)\n",
    "\n",
    "print(x.shape, out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input -> first block \n",
    "in_shape = (3, 64, 64)\n",
    "in_c = in_shape[0]\n",
    "\n",
    "b1 = nn.Sequential(\n",
    "    nn.Conv2d(in_c, 64, kernel_size=7, stride=2, padding=3),\n",
    "    nn.BatchNorm2d(64),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    ")\n",
    "m = b1\n",
    "\n",
    "\n",
    "x = torch.ones(1,*in_shape)\n",
    "out = m(x)\n",
    "\n",
    "print(x.shape, out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each of the subsequent blocks contain 2 residual operations, where the output channel\n",
    "# is doubled and the resolution (ie. h,w) is halved\n",
    "def get_resnet_block(in_c, out_c, *, \n",
    "                     n_residuals=2,\n",
    "                     first_block=False,\n",
    "                    ) -> List[nn.Module]:\n",
    "    # First residual: In the first block, we don't adjust the (h,w) by half because \n",
    "    # the input is already processed by a MaxPool layer\n",
    "    if first_block:\n",
    "        use_1x1conv = False if in_c == out_c else True\n",
    "        res0 = Residual(in_c, out_c, stride=1, use_1x1conv=use_1x1conv)\n",
    "\n",
    "    else:\n",
    "        res0 = Residual(in_c, out_c, stride=2, use_1x1conv=True)\n",
    "\n",
    "    block = [res0]\n",
    "    # Add subsequence residuals \n",
    "    for i in range(n_residuals-1):\n",
    "        block.append(Residual(out_c, out_c, \n",
    "                              stride=1, use_1x1conv=False))\n",
    "    return block\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test\n",
    "in_shape = (3, 64, 64)\n",
    "in_c = in_shape[0]\n",
    "\n",
    "# m = nn.Sequential(\n",
    "#     *get_resnet_block(in_c, 2*in_c, first_block=True)\n",
    "# )\n",
    "m = nn.Sequential(\n",
    "    *get_resnet_block(in_c, 2*in_c, first_block=False)\n",
    ")\n",
    "x = torch.ones(1,*in_shape)\n",
    "out = m(x)\n",
    "\n",
    "print(x.shape, out.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's create a full ResNet module\n",
    "- b1 : convolution before residual blocks start\n",
    "  input -> (conv-bn-relu) -> maxpool(1/2)\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNetEncoder(nn.Module):\n",
    "    \"\"\"\n",
    "    input -> b1: (conv-bn-relu-maxpool(1/2))\n",
    "          -> resnet_blocks: nn.Sequential of resnet blocks\n",
    "               Each block has 2 residual units: (bn-relu-conv, bn-relu-conv)\n",
    "          -> Flatten()\n",
    "          -> FC(len_flatten, out_dim) \n",
    "          -> out_fn: eg. nn.Tanh(), nn.Sigmoid()\n",
    "    \"\"\"\n",
    "    def __init__(self, \n",
    "                 in_c: int, \n",
    "                 hidden_dims: List[int],  \n",
    "                 act_fn=nn.ReLU(inplace=True)):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.in_c = in_c\n",
    "        self.hidden_dims = hidden_dims\n",
    "        self.act_fn = act_fn\n",
    "        \n",
    "        n0 = hidden_dims[0]\n",
    "        self.b1 = nn.Sequential(\n",
    "            nn.Conv2d(in_c, n0, kernel_size=3, stride=1, padding=1), # (bs,n0,h,w)\n",
    "            nn.BatchNorm2d(n0),\n",
    "            self.act_fn,\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1) # (bs, n0, h/2, w/2)\n",
    "        )\n",
    "        \n",
    "        blocks = []\n",
    "        for i, (in_c, out_c) in enumerate(zip(hidden_dims, hidden_dims[1:])):\n",
    "            is_first = (i == 0)\n",
    "            blocks.extend(get_resnet_block(in_c, out_c, first_block=is_first))\n",
    "            \n",
    "        self.resnet_blocks = nn.Sequential(*blocks)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        x -> b1 (conv-bn-act-maxpool(1/2)) -> resnet_blocks -> out\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        out : (BS, hidden_dims[-1], last_h, last_w)\n",
    "        \"\"\"\n",
    "        out = self.b1(x)\n",
    "        out = self.resnet_blocks(out)\n",
    "        return out\n",
    "    \n",
    "                          \n",
    "                    \n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_resnet_block' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-57-804b266e4108>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0min_c\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0min_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mhidden_dims\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mResNetEncoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_c\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_dims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0min_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-56-4bfdb63928c8>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, in_c, hidden_dims, act_fn)\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0min_c\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_c\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_dims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_dims\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0mis_first\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m             \u001b[0mblocks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_resnet_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_c\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_c\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfirst_block\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_first\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresnet_blocks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'get_resnet_block' is not defined"
     ]
    }
   ],
   "source": [
    "in_shape = (3,64,64)\n",
    "in_c = in_shape[0]\n",
    "hidden_dims = [32,32,64,128]\n",
    "m = ResNetEncoder(in_c, hidden_dims)\n",
    "\n",
    "x = torch.ones(1,*in_shape)\n",
    "out = m(x)\n",
    "\n",
    "print(x.shape, out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": "true"
   },
   "source": [
    "# Resnet Decoder\n",
    "- Jan 29, 2021"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Residual unit with deconvolutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualDeconv(nn.Module):\n",
    "    \"\"\"A module that implements a single flow of residual operation for ResNet.\n",
    "    Each conv layer uses kernel of size 3x3, stride=stride, and padding=1.\n",
    "    First the input's (h,w) are shrinked by `stride`, then the num of channels\n",
    "    is increased to out_c via subsequent conv operations.\n",
    "    \n",
    "    \n",
    "    input ---> (bn-relu-convTranspose2d) -> z1 ---> (bn-relu-convTranspose2d) -> z2 ---> out\n",
    "            |                                                                     ^\n",
    "            |                                                                     |\n",
    "            |                                                                     +\n",
    "            ----------------->  (upsampling) --------------------------------------\n",
    "    \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    stride : int\n",
    "        Stride parameter of the first convTranspose layer. Use stride = 2 as a way to \n",
    "        double the (h,w) of the input\n",
    "        \n",
    "        \n",
    "    use_upsampling : bool\n",
    "        Applies an upsampling and 1x1 conv to the input to adjust its (h,w) and \n",
    "        n_channel (in_c) to be equal to the output's n_chhanel (out_c).\n",
    "        Thus, it must be set to True whenever the input's num channel or (h,w) need to \n",
    "        be adjusted in order to be added to the second conv's output (z2), ie: \n",
    "        - in_c is different from out_c, or\n",
    "        - `stride` != 1, or\n",
    "        - same shape of input and output, but just want to add 1x1 conv operation\n",
    "        to the input before adding it to the activation after the second conv.\n",
    "\n",
    "    upsampling_type : str\n",
    "        'nearest': use nearest neighbor unsampling (no extra parameters) followed by 1x1 conv\n",
    "        'deconv': use convTranspose2d with `stride` to adjust both (h,w) and num of channels\n",
    "        \n",
    "        \n",
    "    `forward(x)` returns\n",
    "    -----------\n",
    "    out = model(x) returns a batch of tensors whose size is :\n",
    "        (BS, out_c, in_h/stride, in_w/stride)\n",
    "        \n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, in_c, out_c, \n",
    "                 *,\n",
    "                 stride=2,\n",
    "                 use_upsampling: bool = True,\n",
    "                 upsampling_type: str = 'deconv',\n",
    "                 norm_input: bool = True,\n",
    "                 act_fn=nn.ReLU(inplace=True),\n",
    "                 **kwargs\n",
    "                ):\n",
    "        \"\"\"\n",
    "        To double the input's (h,w), ie. stride=2,\n",
    "            use kernel_size=3, padding=1, stride=2, output_padding=1\n",
    "        When the output needs bo have the same (h,w) as the input, ie. stride=1, \n",
    "            use output_padding = 0 \n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        deconv_kwargs = {'kernel_size': 3, 'padding': 1}#, 'output_padding':1}\n",
    "        deconv_kwargs.update(kwargs)\n",
    "        \n",
    "        self.stride = stride\n",
    "        self.outp = 1 if stride==2 else 0\n",
    "        self.use_upsampling = use_upsampling\n",
    "        if in_c != out_c or stride>1:\n",
    "            assert self.use_upsampling==True, \"Input needs to be adjusted in (h,w) and/or num channels. Set use_upsampling=True\"\n",
    "        self.upsampling = None\n",
    "        if upsampling_type == 'nearest':\n",
    "            self.upsampling = nn.Sequential(\n",
    "                nn.UpsamplingNearest2d(scale_factor=self.stride),\n",
    "                nn.ConvTranspose2d(in_c, out_c, **deconv_kwargs, stride=1, output_padding=0)\n",
    "            )\n",
    "        elif upsampling_type == 'deconv':\n",
    "            #Use 1x1 conv to do both channelwise and resolutionwise expansion\n",
    "            self.upsampling = nn.ConvTranspose2d(in_c, out_c,  **deconv_kwargs, stride=self.stride, output_padding=self.outp)\n",
    "        self.norm_input = norm_input\n",
    "        \n",
    "        self.bn1 = nn.BatchNorm2d(in_c)\n",
    "        self.deconv1 = nn.ConvTranspose2d(in_c, out_c, **deconv_kwargs, stride=self.stride, output_padding=self.outp)\n",
    "        \n",
    "        self.bn2 = nn.BatchNorm2d(out_c)\n",
    "        self.deconv2 = nn.ConvTranspose2d(out_c, out_c, **deconv_kwargs, stride=1, output_padding=0)\n",
    "        \n",
    "        self.act_fn = act_fn\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Returns\n",
    "        -------\n",
    "        out = model(x) returns a batch of tensors whose size is :\n",
    "        (BS, out_c, in_h * stride, in_w *stride)\n",
    "        \n",
    "        \"\"\"\n",
    "        if self.norm_input:\n",
    "            z = self.deconv1(self.act_fn(self.bn1(x)))\n",
    "        else:\n",
    "            z = self.deconv1(x) # ; print(z.shape);breakpoint()\n",
    "        z = self.deconv2(self.act_fn(self.bn2(z))) # ; print(z.shape);breakpoint()\n",
    "        \n",
    "        if self.use_upsampling:\n",
    "            x = self.upsampling(x) # ; print(x.shape);breakpoint()\n",
    "        z = z + x # ; print(z.shape);breakpoint()\n",
    "        \n",
    "        return self.act_fn(z)\n",
    "            \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 64, 64]) torch.Size([1, 32, 128, 128])\n"
     ]
    }
   ],
   "source": [
    "# Test Residual: in_c --> out_c is not the same\n",
    "in_shape = (3, 64,64)\n",
    "in_c = in_shape[0]\n",
    "out_c = 32\n",
    "stride = 2\n",
    "use_upsampling=True\n",
    "upsampling_type='deconv'\n",
    "norm_input = True\n",
    "m = ResidualDeconv(in_c, \n",
    "                   out_c, \n",
    "                   use_upsampling=True, \n",
    "                   upsampling_type=upsampling_type,\n",
    "                   norm_input=norm_input,\n",
    "                   stride=stride\n",
    "                  )\n",
    "\n",
    "\n",
    "x = torch.ones(1, *in_shape)\n",
    "out = m(x)\n",
    "\n",
    "print(x.shape, out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 32, 8, 8]) torch.Size([1, 32, 16, 16])\n"
     ]
    }
   ],
   "source": [
    "# Test Residual: in_c --> out_c is the same\n",
    "in_shape = (32, 8, 8)\n",
    "in_c = in_shape[0]\n",
    "out_c = in_c\n",
    "stride = 2\n",
    "use_upsampling=True\n",
    "upsampling_type='deconv'\n",
    "norm_input = False\n",
    "\n",
    "m = ResidualDeconv(in_c, \n",
    "                   out_c, \n",
    "                   use_upsampling=use_upsampling, \n",
    "                   upsampling_type=upsampling_type,\n",
    "                   norm_input=norm_input,\n",
    "                   stride=stride\n",
    "                  )\n",
    "\n",
    "\n",
    "x = torch.ones(1,*in_shape)\n",
    "out = m(x)\n",
    "\n",
    "print(x.shape, out.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ResNetDeconv Blocks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input -> first block \n",
    "in_shape = (3, 64, 64)\n",
    "in_c = in_shape[0]\n",
    "\n",
    "b1 = nn.Sequential(\n",
    "    nn.Conv2d(in_c, 64, kernel_size=7, stride=2, padding=3),\n",
    "    nn.BatchNorm2d(64),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    ")\n",
    "m = b1\n",
    "\n",
    "\n",
    "x = torch.ones(1,*in_shape)\n",
    "out = m(x)\n",
    "\n",
    "print(x.shape, out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each of the subsequent blocks contain 2 residual operations, where the output channel\n",
    "# is doubled and the resolution (ie. h,w) is halved\n",
    "def get_resnet_deconv_block(\n",
    "    in_c, out_c, *, \n",
    "    n_residuals=2,\n",
    "    first_block=False,\n",
    ") -> List[nn.Module]:\n",
    "    # First residual: In the first block, we don't apply the batchnorm because \n",
    "    # the input is already processed with a batchnorm.\n",
    "    \n",
    "    norm_input = True\n",
    "    if first_block:\n",
    "        norm_input = False \n",
    "    res0 = ResidualDeconv(in_c, out_c, stride=2, use_upsampling=True, norm_input=norm_input)\n",
    "\n",
    "    block = [res0]\n",
    "    # Add subsequence residuals \n",
    "    for i in range(n_residuals-1):\n",
    "        block.append(ResidualDeconv(out_c, out_c, stride=1, \n",
    "                                    use_upsampling=False, norm_input=True)\n",
    "                    )\n",
    "    return block\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 64, 64]) torch.Size([1, 6, 128, 128])\n"
     ]
    }
   ],
   "source": [
    "# Test\n",
    "in_shape = (3, 64, 64)\n",
    "in_c = in_shape[0]\n",
    "\n",
    "# m = nn.Sequential(\n",
    "#     *get_resnet_block(in_c, 2*in_c, first_block=True)\n",
    "# )\n",
    "m = nn.Sequential(\n",
    "    *get_resnet_deconv_block(in_c, 2*in_c, first_block=False)\n",
    ")\n",
    "x = torch.ones(1,*in_shape)\n",
    "out = m(x)\n",
    "\n",
    "print(x.shape, out.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's create a full ResNetDecoder module\n",
    "Each block contains 2 residual deconv units.\n",
    "If the block is the first block in the net, then the first unit of the block does not apply\n",
    "batchnorm to the input.\n",
    "\n",
    "In each block, the first residual unit doubles both the n_channels and resolutions (height,width) by\n",
    "setting:\n",
    "  out_c = 2*in_c, and\n",
    "  stride = 2\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNetDecoder(nn.Module):\n",
    "    \"\"\"x -> resnet_deconv_blocks -> out\n",
    "\n",
    "    input -> resnet_deconv_blocks: nn.Sequential of resnet_deconv blocks\n",
    "                Each block has 2 residual units: (bn-relu-conv, bn-relu-conv),\n",
    "                except the first block, whose first residual unit doesn't apply (bn-relu)\n",
    "    out : (BS, hidden_dims[-1]=in_channels, in_h, in_w)\n",
    "                \n",
    "    \"\"\"\n",
    "    def __init__(self, \n",
    "                 nfs: List[int],  \n",
    "                 act_fn=nn.ReLU(inplace=True)):\n",
    "        super().__init__()\n",
    "        self.act_fn = act_fn\n",
    "        \n",
    "        blocks = []\n",
    "        for i, (in_c, out_c) in enumerate(zip(nfs, nfs[1:])):\n",
    "            is_first = (i == 0)\n",
    "            blocks.extend(get_resnet_deconv_block(in_c, out_c, first_block=is_first))\n",
    "        self.resnet_blocks = nn.Sequential(*blocks)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        x -> resnet_deconv_blocks -> out\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        out : (BS, hidden_dims[-1]=in_channels, in_h, in_w)\n",
    "        \"\"\"\n",
    "        out = self.resnet_deconv_blocks(x)\n",
    "        return out\n",
    "    \n",
    "                          \n",
    "                    \n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 128, 2, 2]) torch.Size([1, 3, 16, 16])\n"
     ]
    }
   ],
   "source": [
    "from src.models.resnet_deconv import ResNetDecoder\n",
    "\n",
    "in_shape = (128,2,2)\n",
    "in_c = in_shape[0]\n",
    "nfs = [in_c, in_c//2, in_c//4, 3]\n",
    "m = ResNetDecoder(nfs)\n",
    "\n",
    "x = torch.ones(1,*in_shape)\n",
    "out = m(x)\n",
    "\n",
    "print(x.shape, out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:test]",
   "language": "python",
   "name": "conda-env-test-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
